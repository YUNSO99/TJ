{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d72f41-2584-4fbd-b508-312ee9a159a8",
   "metadata": {},
   "source": [
    "# Moscow Marathon Full Results 2018\n",
    "\n",
    "\n",
    "## 1_full_results_mm_2018.csv\n",
    "\n",
    "Columns : {Bib, finish_time_sec, finish_time_result, race, pace_sec, pace(minpkm), pace(kmph), half_pace_sec, half_pace(minpkm), half_pace(kmph), gender_en, agev name_en, location_city_ru, location_city_en, country_code_alpha_3, flag_DNF, flag_all_split_exist, race_uniform_index}\n",
    "\n",
    "Data : {1, 8911, 2h 28min 31sec, 42.195 km, 211.1861595, 3:31 min/km 17.0 km/h, 208.3185212, 3:28 min/km, 17.3 km/h, Female, 30, Sardana Trofimova, –Ø–∫—É—Ç—Å–∫, Yakutsk, RUS, 0, 1, 0.000132899}\n",
    "\n",
    "## 1_split_results_mm_2018.csv\n",
    "\n",
    "Columns : {bib, split_name, split, split_time_sec, split_time_result, split_pace_sec, split_pace(minpkm), split_pace(kmph), split_uniform_index}\n",
    "\n",
    "Data : {11, Kirui, Geoffrey, 24, M, Keringet, KEN, 0:15:25, 0:30:28, 0:45:44, 1:01:15, 1:04:35, 1:16:59, 1:33:01, 1:48:19, 2:02:53, 0:04:57, - 2:09:37, 1, 1, 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998cb8bc-a1de-40a6-913a-833796954086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "full_df = pd.read_csv('./data/1_full_results_mm_2018.csv')\n",
    "split_df = pd.read_csv('./data/1_split_results_mm_2018.csv')\n",
    "\n",
    "# bib 통일\n",
    "full_df['bib'] = full_df['bib'].astype(str)\n",
    "split_df['bib'] = split_df['bib'].astype(str)\n",
    "\n",
    "# --------------------------\n",
    "# split_time_sec pivot (5K~40K만)\n",
    "split_time = split_df.pivot_table(index='bib', columns='split_name', values='split_time_sec')\n",
    "\n",
    "# Marathon 열 제거\n",
    "split_time = split_time.drop(columns=['Half marathon','Marathon'], errors='ignore')\n",
    "\n",
    "# ' km' 제거 후 'K' 붙이기\n",
    "split_time.columns = [col.replace(' km', '') + 'K' for col in split_time.columns]\n",
    "split_time = split_time.apply(pd.to_numeric, errors='coerce')\n",
    "split_time.reset_index(inplace=True)\n",
    "\n",
    "# --------------------------\n",
    "# split_pace_sec pivot (5p~40p만)\n",
    "split_pace = split_df.pivot_table(index='bib', columns='split_name', values='split_pace_sec')\n",
    "split_pace = split_pace.drop(columns=['Half marathon', 'Marathon'], errors='ignore')\n",
    "\n",
    "split_pace.columns = [col.replace(' km', '') + 'p' for col in split_pace.columns]\n",
    "split_pace = split_pace.apply(pd.to_numeric, errors='coerce')\n",
    "split_pace.reset_index(inplace=True)\n",
    "\n",
    "#--------------------------------------\n",
    "# Half marathon 기록 추출\n",
    "half_time = split_df[split_df['split_name'] == 'Half marathon'][['bib', 'split_time_sec']].copy()\n",
    "half_time.rename(columns={'split_time_sec': 'Half'}, inplace=True)\n",
    "\n",
    "half_pace = split_df[split_df['split_name'] == 'Half marathon'][['bib', 'split_pace_sec']].copy()\n",
    "half_pace.rename(columns={'split_pace_sec': 'Halfp'}, inplace=True)\n",
    "\n",
    "# 병합\n",
    "split_time = split_time.merge(half_time, how='left', on='bib')\n",
    "split_pace = split_pace.merge(half_pace, how='left', on='bib')\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 필요한 컬럼 선택 및 전처리\n",
    "reduced_df = full_df[['bib', 'age', 'gender_en', 'country_code_alpha_3', 'finish_time_sec']].copy()\n",
    "reduced_df.rename(columns={\n",
    "    'bib': 'Bib',\n",
    "    'age': 'Age',\n",
    "    'gender_en': 'M/F',\n",
    "    'country_code_alpha_3': 'Country',\n",
    "    'finish_time_sec': 'Final_Time'\n",
    "}, inplace=True)\n",
    "\n",
    "# Final_Time이 NaN인 경우 제거\n",
    "reduced_df = reduced_df.dropna(subset=['Final_Time'])\n",
    "\n",
    "# Age_group (19이하 → 19, ..., 70 이상 → 70)\n",
    "def age_group(age):\n",
    "    if age <= 19:\n",
    "        return 19\n",
    "    elif age >= 70:\n",
    "        return 70\n",
    "    else:\n",
    "        return (age // 5) * 5 + 4  # 20~24 → 24, 25~29 → 29, ...\n",
    "\n",
    "reduced_df['Age_group'] = reduced_df['Age'].apply(age_group)\n",
    "\n",
    "# M/F: Male → 0, Female → 1\n",
    "reduced_df['M/F'] = reduced_df['M/F'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "# Sub 그룹핑\n",
    "def set_sub_group(seconds):\n",
    "    if pd.isna(seconds):\n",
    "        return pd.NA\n",
    "    hours = seconds / 3600\n",
    "    if hours < 3:\n",
    "        return 3\n",
    "    elif hours < 4:\n",
    "        return 4\n",
    "    elif hours < 5:\n",
    "        return 5\n",
    "    elif hours < 6:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "reduced_df['Sub'] = reduced_df['Final_Time'].apply(set_sub_group).astype('Int64')\n",
    "\n",
    "# --------------------------\n",
    "# 병합\n",
    "merged = reduced_df.merge(split_time, how='left', left_on='Bib', right_on='bib')\n",
    "merged = merged.merge(split_pace, how='left', on='bib')\n",
    "merged.drop(columns=['bib'], inplace=True)\n",
    "\n",
    "# Dataset 컬럼 추가\n",
    "merged['Dataset'] = 'M'\n",
    "\n",
    "merged['Year'] = 2018\n",
    "\n",
    "merged.info()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 컬럼 순서 지정 (5~40K, 5~40p만 포함)\n",
    "pace_cols = [f'{k}p' for k in range(5, 45, 5)]\n",
    "time_cols = [f'{k}K' for k in range(5, 45, 5)]\n",
    "\n",
    "columns_order = ['Bib', 'Age_group', 'M/F', 'Country'] + \\\n",
    "                pace_cols + ['Final_Time', 'Sub'] + \\\n",
    "                time_cols + ['Dataset'] + \\\n",
    "                ['Year', 'Half', 'Halfp']\n",
    "\n",
    "# 존재하는 컬럼만 유지\n",
    "columns_order = [col for col in columns_order if col in merged.columns]\n",
    "\n",
    "# 결측치 제거\n",
    "Moscow_df = merged[columns_order].dropna()\n",
    "\n",
    "# Bib 재설정\n",
    "Moscow_df['Bib'] = range(1, len(Moscow_df) + 1)\n",
    "cols = Moscow_df.columns.tolist()\n",
    "cols.remove('Bib')\n",
    "Moscow_df = Moscow_df[['Bib'] + cols]\n",
    "\n",
    "# int 변환\n",
    "int_cols = Moscow_df.columns.difference(['Country', 'Dataset'])\n",
    "Moscow_df[int_cols] = Moscow_df[int_cols].astype(int)\n",
    "\n",
    "Moscow_df = Moscow_df[[\"Bib\", \"Age_group\", \"M/F\", \"Country\", \"5p\", \"10p\", \"15p\", \"Halfp\", \"25p\", \"30p\", \"35p\", \"40p\", \"Final_Time\", \"Sub\", \"5K\", \"10K\", \"15K\", \"Half\", \"25K\", \"30K\", \"35K\", \"40K\", \"Dataset\", \"Year\"]]\n",
    "\n",
    "\n",
    "# 저장\n",
    "Moscow_df.to_csv('./data/Moscow_Marathon_Processed.csv', index=False)\n",
    "\n",
    "# 확인\n",
    "print(Moscow_df.head())\n",
    "# Moscow_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3ed32-07ab-4a38-9976-eade76903ebf",
   "metadata": {},
   "source": [
    "# Finishers Boston Marathon 2015, 2016 & 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e608019-0082-42c3-9da0-3453de163d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 로드\n",
    "df_15 = pd.read_csv('./data/marathon_results_2015.csv')\n",
    "df_16 = pd.read_csv('./data/marathon_results_2016.csv')\n",
    "df_17 = pd.read_csv('./data/marathon_results_2017.csv')\n",
    "\n",
    "# 연도 컬럼 추가\n",
    "df_15['Year'] = 2015\n",
    "df_16['Year'] = 2016\n",
    "df_17['Year'] = 2017\n",
    "\n",
    "# 데이터 통합\n",
    "df = pd.concat([df_15, df_16, df_17], ignore_index=True)\n",
    "\n",
    "df = df.rename(columns={\"Half\": \"HalfK\"})\n",
    "\n",
    "\n",
    "# 불필요한 컬럼 제거\n",
    "drop_cols = ['Unnamed: 0', 'Unnamed: 8', 'Unnamed: 9', 'State', 'Citizen', 'Proj Time']\n",
    "df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
    "\n",
    "# 시간형 컬럼 처리 대상: 21K는 제거 대상\n",
    "time_cols = ['5K', '10K', '15K', 'HalfK', '25K', '30K', '35K', '40K', 'Pace', 'Official Time']\n",
    "for col in time_cols:\n",
    "    df[col] = pd.to_timedelta(df[col], errors='coerce')\n",
    "\n",
    "# 초 단위로 변환\n",
    "for col in ['5K', '10K', '15K', 'HalfK', '25K', '30K', '35K', '40K', 'Official Time']:\n",
    "    df[col] = df[col].dt.total_seconds()\n",
    "\n",
    "# 컬럼명 변경\n",
    "df.rename(columns={'Official Time': 'Final_Time'}, inplace=True)\n",
    "\n",
    "# 페이스 계산 (21K 제외)\n",
    "distance_km = {'5K': 5, '10K': 10, '15K': 15, 'HalfK': 21.0975, '25K': 25, '30K': 30, '35K': 35, '40K': 40}\n",
    "for dist, km in distance_km.items():\n",
    "    pace_col = dist.replace('K', 'p')\n",
    "    df[pace_col] = df[dist] / km\n",
    "\n",
    "# Age_group 지정\n",
    "def age_group(age):\n",
    "    if age < 20:\n",
    "        return 19\n",
    "    elif age < 25:\n",
    "        return 24\n",
    "    elif age < 30:\n",
    "        return 29\n",
    "    elif age < 35:\n",
    "        return 34\n",
    "    elif age < 40:\n",
    "        return 39\n",
    "    elif age < 45:\n",
    "        return 44\n",
    "    elif age < 50:\n",
    "        return 49\n",
    "    elif age < 55:\n",
    "        return 54\n",
    "    elif age < 60:\n",
    "        return 59\n",
    "    elif age < 65:\n",
    "        return 64\n",
    "    elif age < 70:\n",
    "        return 69\n",
    "    else:\n",
    "        return 70\n",
    "\n",
    "df['Age_group'] = df['Age'].apply(age_group)\n",
    "\n",
    "# 성별 인코딩\n",
    "df['M/F'] = df['M/F'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Sub (시간 그룹)\n",
    "def sub_group(time_sec):\n",
    "    hours = time_sec / 3600\n",
    "    if hours <= 3:\n",
    "        return 3\n",
    "    elif hours <= 4:\n",
    "        return 4\n",
    "    elif hours <= 5:\n",
    "        return 5\n",
    "    elif hours <= 6:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "df['Sub'] = df['Final_Time'].apply(sub_group)\n",
    "\n",
    "# 필요한 컬럼만 추출\n",
    "base_cols = ['Bib', 'Age_group', 'M/F', 'Country']\n",
    "pace_cols = [k.replace('K', 'p') for k in distance_km.keys()]\n",
    "time_cols = list(distance_km.keys())\n",
    "final_cols = ['Final_Time', 'Sub']\n",
    "df['Dataset'] = 'B'\n",
    "\n",
    "ordered_cols = base_cols + pace_cols + final_cols + time_cols + ['Dataset', 'Year']\n",
    "df = df[ordered_cols]\n",
    "\n",
    "# 결측치 제거 및 Bib 재할당\n",
    "df = df.dropna()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['Bib'] = df.index + 1\n",
    "\n",
    "# 숫자형 컬럼 int로 변환\n",
    "int_cols = df.columns.difference(['Country', 'Dataset'])\n",
    "df[int_cols] = df[int_cols].astype(int)\n",
    "\n",
    "df = df.rename(columns={\"HalfK\": \"Half\"})\n",
    "\n",
    "\n",
    "# 저장\n",
    "df.to_csv('./data/boston_processed.csv', index=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(df.head())\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef1d66-ef92-4579-aa23-33c3da631e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "boston_path = './data/boston_processed.csv'\n",
    "moscow_path = './data/Moscow_Marathon_Processed.csv'\n",
    "\n",
    "# 데이터 불러오기\n",
    "df_boston = pd.read_csv(boston_path)\n",
    "df_moscow = pd.read_csv(moscow_path)\n",
    "\n",
    "# 병합 (인덱스 초기화)\n",
    "df_merged = pd.concat([df_boston, df_moscow], ignore_index=True)\n",
    "\n",
    "# Bib 재설정 (1부터 시작)\n",
    "df_merged['Bib'] = range(1, len(df_merged) + 1)\n",
    "\n",
    "# Bib을 맨 앞으로 이동\n",
    "cols = df_merged.columns.tolist()\n",
    "cols.remove('Bib')\n",
    "df_merged = df_merged[['Bib'] + cols]\n",
    "\n",
    "# 결측치 확인 (추가적인 안전 확인)\n",
    "print(\"결측치 존재 여부:\\n\", df_merged.isnull().sum().sum())  # 0이면 OK\n",
    "\n",
    "# Dataset별 샘플 수 확인\n",
    "print(\"Dataset 분포:\\n\", df_merged['Dataset'].value_counts())\n",
    "\n",
    "# 저장\n",
    "df_merged.to_csv('./data/combined_Marathon_Data.csv', index=False)\n",
    "print(f\"✔️ 병합된 데이터 저장 완료! 총 샘플 수: {len(df_merged)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee6a33",
   "metadata": {},
   "source": [
    "# Chicage Marathon 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6203ecd4",
   "metadata": {},
   "source": [
    "#### Chicago Marathon데이터 스크래핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyquery import PyQuery as pq\n",
    "import pandas as pd\n",
    "import re\n",
    "import tqdm\n",
    "import dask.bag as db\n",
    "from dask.distributed import Client\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "BASE_URL = \"https://results.chicagomarathon.com/2021/\"\n",
    "PATH = \"?page={page}&event=MAR&lang=EN_CAP&num_results=1000&pid=list&search%5Bsex%5D={sex}&search%5Bage_class%5D=%25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_split(text, index=1, default=\"\", field_name=\"unknown\"):\n",
    "    try:\n",
    "        return text.split(\"\\n\")[index]\n",
    "    except (IndexError, AttributeError):\n",
    "        split_fail_count[field_name] = split_fail_count.get(field_name, 0) + 1\n",
    "        return default\n",
    "        \n",
    "def parse_page(base_url, path, gender):\n",
    "    resp = requests.get(base_url+path)\n",
    "    d = pq(resp.content)\n",
    "    all_runners = d(\".list-field.type-fullname a\").closest(\".list-group-item .row\")\n",
    "    all_runners_parsed = []\n",
    "    for runner in all_runners.items():\n",
    "        name_country = runner.find(\".type-fullname a\").text()\n",
    "        idp = re.search(\"(?<=idp=)[A-Z0-9_.-]*(?=&)\", runner.find(\".type-fullname a\").attr['href']).group(0)\n",
    "        details_url = base_url + \"?content=detail&idp=\" + idp\n",
    "\n",
    "        data = {\n",
    "            \"name\": name_country[:-6],\n",
    "            \"gender\": gender,\n",
    "            \"country\": name_country[-4:-1],\n",
    "            \"age_class\": safe_split(runner.find(\".type-age_class\").text(), 1),\n",
    "            \"half_time\": safe_split(runner.find(\".type-time\").eq(0).text(), 1),\n",
    "            \"finish_time\": safe_split(runner.find(\".type-time\").eq(1).text(), 1),\n",
    "            \"details_url\": details_url,\n",
    "        }        \n",
    "        all_runners_parsed.append(data)\n",
    "\n",
    "    return all_runners_parsed\n",
    "\n",
    "def get_details(details_url):\n",
    "    x = pq(details_url)\n",
    "    splits = {\n",
    "        \"start\": {\n",
    "            \"time_of_day\": x.find(\".f-starttime_net.last\").text(),\n",
    "            \"time\": \"00:00:00\"\n",
    "        },\n",
    "        \"5km\": {\n",
    "            \"time_of_day\": x.find(\".f-time_05 .time_day\").text(),\n",
    "            \"time\": x.find(\".f-time_05 .time\").text()\n",
    "        },\n",
    "        \"10km\": {\n",
    "            \"time_of_day\": x.find(\".f-time_10 .time_day\").text(),\n",
    "            \"time\": x.find(\".f-time_10 .time\").text()\n",
    "        },\n",
    "        \"15km\": {\n",
    "            \"time_of_day\": x.find(\".f-time_15 .time_day\").text(),\n",
    "            \"time\": x.find(\".f-time_15 .time\").text()\n",
    "        },\n",
    "        \"20km\": {\n",
    "            \"time_of_day\": x.find(\".f-time_20 .time_day\").text(),\n",
    "            \"time\": x.find(\".f-time_20 .time\").text()\n",
    "        },\n",
    "        \"half\": {\n",
    "            \"time_of_day\": x.find(\".f-time_52 .time_day\").text(),\n",
    "            \"time\": x.find(\".f-time_52 .time\").text()\n",
    "        },\n",
    "        \"25km\": {\n",
    "            \"time_of_day\": x.find(\".f-time_25 .time_day\").text(),\n",
    "            \"time\": x.find(\".f-time_25 .time\").text()\n",
    "        },\n",
    "        \"30km\": {\n",
    "            \"time_of_day\": x.find(\".f-time_30 .time_day\").text(),\n",
    "            \"time\": x.find(\".f-time_30 .time\").text()\n",
    "        },\n",
    "        \"35km\": {\n",
    "            \"time_of_day\": x.find(\".f-time_35 .time_day\").text(),\n",
    "            \"time\": x.find(\".f-time_35 .time\").text()\n",
    "        },\n",
    "        \"40km\": {\n",
    "            \"time_of_day\": x.find(\".f-time_40 .time_day\").text(),\n",
    "            \"time\": x.find(\".f-time_40 .time\").text()\n",
    "        },\n",
    "        \"finish\": {\n",
    "            \"time_of_day\": x.find(\".f-time_finish_netto .time_day\").text(),\n",
    "            \"time\": x.find(\".f-time_finish_netto .time\").text()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"bib\": x.find(\".f-start_no_text.last\").text(),\n",
    "        \"city_state\": x.find(\".f-__city_state.last\").text(),\n",
    "        \"splits\": splits,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6480df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runners = []\n",
    "\n",
    "for page in tqdm.tqdm(range(1, 16)):\n",
    "    all_runners += parse_page(BASE_URL, PATH.format(page=page, sex=\"M\"), gender=\"man\")\n",
    "    \n",
    "    \n",
    "for page in tqdm.tqdm(range(1, 13)):\n",
    "    all_runners += parse_page(BASE_URL, PATH.format(page=page, sex=\"W\"), gender=\"woman\")\n",
    "\n",
    "pd.DataFrame(all_runners).to_csv(\"data/runners.csv\", index=None)\n",
    "\n",
    "all_runners = pd.read_csv(\"data/runners.csv\").to_dict(orient=\"records\")\n",
    "\n",
    "client = Client() \n",
    "client\n",
    "\n",
    "len(db.from_sequence(all_runners).map(lambda x: x[\"name\"]).compute())\n",
    "\n",
    "all_runners[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_details(runner):\n",
    "    runner = runner.copy()\n",
    "    try:\n",
    "        details = get_details(runner[\"details_url\"])\n",
    "        runner.update(details)\n",
    "        return runner\n",
    "    except:\n",
    "        print(runner)\n",
    "        return {}\n",
    "    \n",
    "\n",
    "all_with_details = db.from_sequence(all_runners, npartitions=10000).map(add_details).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c96173",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/runners_with_data.json', 'w') as fp:\n",
    "    json.dump(all_with_details, fp)\n",
    "    \n",
    "df = pd.DataFrame(pd.json_normalize(all_with_details))\n",
    "\n",
    "to_drop = [\"splits.start.time\", \"details_url\", \"city_state\", \"finish_time\", \"half_time\", \"name\", \"country\", \"bib\", \"gender\", \"age_class\"] \n",
    "to_drop += [c for c in df.columns if \"time_of_day\" in c]\n",
    "df = df.drop(columns=to_drop)\n",
    "\n",
    "df = df.replace(\"–\", np.nan)\n",
    "\n",
    "df.columns = [c.replace(\"splits.\", \"\") for c in df.columns]\n",
    "df.to_csv(\"./chicago_data.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f27e9",
   "metadata": {},
   "source": [
    "#### Chicago Marathon 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. 시카고 마라톤 원본 데이터 불러오기\n",
    "chicago_df = pd.read_csv(\"./data/chicago_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1478f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 구간 기록 컬럼명을 보스턴 데이터와 동일하게 통일\n",
    "split_mapping = {\n",
    "    '5km.time': '5K',\n",
    "    '10km.time': '10K',\n",
    "    '15km.time': '15K',\n",
    "    '20km.time': '20K',\n",
    "    'half.time': 'Half',\n",
    "    '25km.time': '25K',\n",
    "    '30km.time': '30K',\n",
    "    '35km.time': '35K',\n",
    "    '40km.time': '40K',\n",
    "    'finish.time': 'Final_Time'\n",
    "}\n",
    "chicago_df = chicago_df.rename(columns=split_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95718d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 문자열 형태의 시간 데이터를 pandas timedelta로 변환\n",
    "for col in split_mapping.values():\n",
    "    chicago_df[col] = pd.to_timedelta(chicago_df[col], errors='coerce')\n",
    "\n",
    "# timedelta 형식인 칼럼들 리스트\n",
    "time_cols = [\"5K\", \"10K\", \"15K\", \"20K\", \"Half\", \"25K\", \"30K\", \"35K\", \"40K\", \"Final_Time\"]  \n",
    "\n",
    "# 각 칼럼을 초 단위로 변환하여 새로운 컬럼 추가 (예: '5K_sec', '10K_sec' ...)\n",
    "for col in time_cols:\n",
    "    chicago_df[col] = pd.to_timedelta(chicago_df[col]).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d2a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 성별 표기 통일: man/woman → M/F\n",
    "chicago_df[\"M/F\"] = chicago_df[\"gender\"].map({\"man\": \"0\", \"woman\": \"1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185206f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 각 구간별 페이스 계산 (분/km 기준)\n",
    "dist_cols = [\"5K\", \"10K\", \"15K\", \"20K\", \"Half\", \"25K\", \"30K\", \"35K\", \"40K\"]\n",
    "dists = [5, 10, 15, 20, 21.0975, 25, 30, 35, 40]\n",
    "\n",
    "for col, dist in zip(dist_cols, dists):\n",
    "    chicago_df[col + \"p\"] = chicago_df[col] / (dist)\n",
    "\n",
    "split_mapping = {\n",
    "    '5Kp': '5p',\n",
    "    '10Kp': '10p',\n",
    "    '15Kp': '15p',\n",
    "    '20Kp': '20p',\n",
    "    'Halfp': 'Halfp',\n",
    "    '25Kp': '25p',\n",
    "    '30Kp': '30p',\n",
    "    '35Kp': '35p',\n",
    "    '40Kp': '40p',\n",
    "}\n",
    "chicago_df = chicago_df.rename(columns=split_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6945c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. '.time_of_day'로 끝나는 모든 컬럼 제거\n",
    "cols_to_drop = [col for col in chicago_df.columns if col.endswith(\".time_of_day\")]\n",
    "chicago_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "def age_group_by_upper(val):\n",
    "    try:\n",
    "        return int(str(val).split('-')[1])  # '20-24' → 24\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Age_class 결측값 제거 및 전처리\n",
    "chicago_df = chicago_df[~(chicago_df[\"age_class\"].isna() | (chicago_df[\"age_class\"] == \"MT53\"))]\n",
    "chicago_df['age_class'] = chicago_df['age_class'].map(age_group_by_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처명 수정\n",
    "chicago_df.rename(columns={\"bib\": \"Bib\", \"name\": \"Name\", \"place_gender\": \"Gender\", \"place_overall\": \"Overall\", \"country\": \"Country\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이(Age)를 기준으로 연령대 그룹(구간)으로 나누는 함수 ex. 0~19 -> 20 / 20~29 -> 30\n",
    "\n",
    "def group_calculator(val):\n",
    "    try:\n",
    "        val = float(val)\n",
    "        if val <= 19:\n",
    "            return \"19\"\n",
    "        elif val <= 24:\n",
    "            return \"24\"\n",
    "        elif val <= 29:\n",
    "            return \"29\"\n",
    "        elif val <= 34:\n",
    "            return \"34\"\n",
    "        elif val <= 39:\n",
    "            return \"39\"\n",
    "        elif val <= 44:\n",
    "            return \"44\"\n",
    "        elif val <= 49:\n",
    "            return \"49\"\n",
    "        elif val <= 54:\n",
    "            return \"54\"\n",
    "        elif val <= 59:\n",
    "            return \"59\"\n",
    "        elif val <= 64:\n",
    "            return \"64\"\n",
    "        elif val <= 69:\n",
    "            return \"69\"\n",
    "        else:\n",
    "            return \"70\"\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "    \n",
    "# 연령대 그룹 (20, 30, 40, 60, 80, 100) 생성 후, Age group 컬럼 생성\n",
    "chicago_df['Age_group'] = chicago_df['age_class'].map(group_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완주시간 결측값 제거\n",
    "chicago_df = chicago_df[chicago_df[\"Final_Time\"].notna()]\n",
    "\n",
    "chicago_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26277e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_df = chicago_df.drop(columns=['gender', 'age_class', 'Gender', 'Overall', 'city_state', 'details_url', 'start.time', 'Name', 'finish_time'])\n",
    "\n",
    "\n",
    "chicago_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7679c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목표 그룹 함수 정의\n",
    "def time_group(t):\n",
    "    if t < 10800.0:\n",
    "        return \"3\"\n",
    "    elif t < 14400.0:\n",
    "        return \"4\"\n",
    "    elif t < 18000.0:\n",
    "        return \"5\"\n",
    "    elif t < 21600.0:\n",
    "        return \"6\"\n",
    "    else:\n",
    "        return \"7\"\n",
    "\n",
    "# 그룹 컬럼 생성\n",
    "chicago_df['Sub'] = chicago_df['Final_Time'].apply(time_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf647044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 총 행 수\n",
    "num_rows = len(chicago_df)\n",
    "\n",
    "# 중복 없이 무작위 숫자 생성 (예: 100000 ~ 999999 사이)\n",
    "chicago_df[\"Bib\"] = np.random.choice(range(1, num_rows+1), size=num_rows, replace=False)\n",
    "\n",
    "chicago_df[\"Dataset\"] = \"C\"\n",
    "\n",
    "chicago_df[\"Year\"] = 2021\n",
    "\n",
    "\n",
    "\n",
    "chicago_df = chicago_df[[\"Bib\", \"Age_group\", \"M/F\", \"Country\", \"5p\", \"10p\", \"15p\", \"Halfp\", \"25p\", \"30p\", \"35p\", \"40p\", \"Final_Time\", \"Sub\", \"5K\", \"10K\", \"15K\", \"Half\", \"25K\", \"30K\", \"35K\", \"40K\", \"Dataset\", \"Year\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 완료된 파일 저장\n",
    "chicago_df.to_csv(\"./data/chicago_data_processed.csv\", index=False)\n",
    "print(\"[✓] chicago_data_processed.csv 저장 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974543f5",
   "metadata": {},
   "source": [
    "# 최종 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc67c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 각 데이터셋 불러오기\n",
    "combined_df = pd.read_csv(\"./data/Combined_Marathon_Data.csv\")      # 보스턴 등 기존 데이터\n",
    "chicago_df = pd.read_csv(\"./data/chicago_data_processed.csv\")       # 시카고 데이터\n",
    "\n",
    "# 두 데이터셋을 하나로 병합 (인덱스 재정렬 포함)\n",
    "merged_df = pd.concat([combined_df, chicago_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186935f-fb9e-463d-ab32-51bd2f9a42af",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_M = (merged_df['Dataset'] == 'M').sum()\n",
    "count_B = (merged_df['Dataset'] == 'B').sum()\n",
    "count_C = (merged_df['Dataset'] == 'C').sum()\n",
    "\n",
    "print(f\"Dataset = 'M'인 행 수: {count_M}\")\n",
    "print(f\"Dataset = 'B'인 행 수: {count_B}\")\n",
    "print(f\"Dataset = 'C'인 행 수: {count_C}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e590a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba81a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218f1fa-bf40-435c-9020-ed6c6957b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv파일로 저장\n",
    "merged_df.to_csv(\"./data/merged_marathon_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d5b9a",
   "metadata": {},
   "source": [
    "# 기상 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc55489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "\n",
    "# --- 1. 레이스 정보 정의 (사용자가 ★★★반드시★★★ 정확하게 채워야 하는 부분) ---\n",
    "# (Dataset_ID, Year) : {'date': 'YYYY-MM-DD', 'lat': 위도, 'lon': 경도, 'location_name': '도시명', 'timezone': '도시타임존'}\n",
    "RACE_INFO_LOOKUP = {\n",
    "    # 보스턴 정보 (예시, 실제 값으로 확인/수정 필요)\n",
    "    ('B', 2015): {'date': '2015-04-20', 'lat': 42.3601, 'lon': -71.0589, 'location_name': 'Boston', 'timezone': 'America/New_York'},\n",
    "    ('B', 2016): {'date': '2016-04-18', 'lat': 42.3601, 'lon': -71.0589, 'location_name': 'Boston', 'timezone': 'America/New_York'},\n",
    "    ('B', 2017): {'date': '2017-04-17', 'lat': 42.3601, 'lon': -71.0589, 'location_name': 'Boston', 'timezone': 'America/New_York'},\n",
    "    # 모스크바 정보 (예시, 실제 값으로 확인/수정 필요)\n",
    "    ('M', 2018): {'date': '2018-09-23', 'lat': 55.7558, 'lon': 37.6173, 'location_name': 'Moscow', 'timezone': 'Europe/Moscow'},\n",
    "    # 시카고 정보 (★ 사용자가 추가해야 할 예시)\n",
    "    ('C', 2021): {'date': '2021-10-10', 'lat': 41.8781, 'lon': -87.6298, 'location_name': 'Chicago', 'timezone': 'America/Chicago'},\n",
    "    # ... (만약 다른 연도나 데이터셋('Dataset' 컬럼의 다른 값)이 있다면 모두 추가) ...\n",
    "}\n",
    "\n",
    "API_URL = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "RACE_START_HOUR = 9  # 오전 9시 (레이스 시작 평균 시간)\n",
    "RACE_END_HOUR = 16 # 오후 4시 (대부분의 주자 완주 시간 고려)\n",
    "\n",
    "# --- 2. 날씨 데이터 가져오기 함수 (이전과 동일 또는 약간 개선) ---\n",
    "def fetch_race_window_weather_for_event(latitude, longitude, date_str, timezone=\"Etc/GMT\"):\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": date_str,\n",
    "        \"end_date\": date_str,\n",
    "        \"hourly\": [\"temperature_2m\", \"relativehumidity_2m\"],\n",
    "        \"timezone\": timezone\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(API_URL, params=params)\n",
    "        print(f\"Fetching URL for {date_str} at ({latitude},{longitude}), TZ={timezone}: {response.url}\")\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        hourly_data = data.get('hourly', {})\n",
    "        time_stamps_iso = hourly_data.get('time', [])\n",
    "        temperatures_hourly = hourly_data.get('temperature_2m', [])\n",
    "        humidities_hourly = hourly_data.get('relativehumidity_2m', [])\n",
    "\n",
    "        if not (time_stamps_iso and isinstance(temperatures_hourly, list) and isinstance(humidities_hourly, list)):\n",
    "            print(f\"Warning: 날씨 API 응답에 필요한 정보 부족. Date: {date_str}\")\n",
    "            if isinstance(data, dict) and 'reason' in data: print(f\"API Error Reason: {data['reason']}\")\n",
    "            return None, None\n",
    "\n",
    "        race_window_temps, race_window_humidities = [], []\n",
    "        for i, time_iso in enumerate(time_stamps_iso):\n",
    "            try:\n",
    "                current_hour = dt.fromisoformat(time_iso).hour\n",
    "                if RACE_START_HOUR <= current_hour <= RACE_END_HOUR:\n",
    "                    if i < len(temperatures_hourly) and temperatures_hourly[i] is not None:\n",
    "                        race_window_temps.append(temperatures_hourly[i])\n",
    "                    if i < len(humidities_hourly) and humidities_hourly[i] is not None:\n",
    "                        race_window_humidities.append(humidities_hourly[i])\n",
    "            except (IndexError, ValueError) as e_parse:\n",
    "                print(f\"Warning: 시간 파싱/데이터 접근 오류 ({date_str}, index: {i}): {e_parse}\")\n",
    "                continue\n",
    "        \n",
    "        avg_temp = sum(race_window_temps) / len(race_window_temps) if race_window_temps else None\n",
    "        avg_humidity = sum(race_window_humidities) / len(race_window_humidities) if race_window_humidities else None\n",
    "        \n",
    "        if avg_temp is None or avg_humidity is None:\n",
    "            print(f\"Warning: 레이스 시간 창 내 유효 데이터 부족. Date: {date_str}, Temps: {len(race_window_temps)}, Humids: {len(race_window_humidities)}\")\n",
    "        return avg_temp, avg_humidity\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"Error: 날씨 데이터 HTTP 오류 ({date_str}): {http_err.response.status_code if http_err.response else 'Unknown'}\")\n",
    "        if hasattr(http_err, 'response') and http_err.response is not None and http_err.response.text: \n",
    "            print(f\"Response content: {http_err.response.text}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred for {date_str}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# --- 3. 메인 데이터프레임에 날씨 정보 병합하는 함수 (이전과 동일 또는 약간 개선) ---\n",
    "def add_weather_to_marathon_data(df_marathon: pd.DataFrame, year_col: str, dataset_col: str) -> pd.DataFrame:\n",
    "    # 입력 데이터프레임 복사본 사용\n",
    "    df_to_process = df_marathon.copy()\n",
    "\n",
    "    if year_col not in df_to_process.columns or dataset_col not in df_to_process.columns:\n",
    "        print(f\"Error: DataFrame에 '{year_col}' 또는 '{dataset_col}' 컬럼이 없습니다.\")\n",
    "        df_to_process['temperature_race'] = pd.NA\n",
    "        df_to_process['humidity_race'] = pd.NA\n",
    "        return df_to_process\n",
    "\n",
    "    weather_data_cache = {} \n",
    "\n",
    "    # 연도 컬럼을 정수형으로 변환 (RACE_INFO_LOOKUP 키와 매칭 위함)\n",
    "    try:\n",
    "        df_to_process[year_col] = pd.to_numeric(df_to_process[year_col], errors='coerce').astype('Int64') # Nullable Integer\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: '{year_col}'을 정수형으로 변환하는 데 실패했습니다. ({e}). 결측치가 발생할 수 있습니다.\")\n",
    "\n",
    "    unique_events = df_to_process[[year_col, dataset_col]].dropna().drop_duplicates()\n",
    "    \n",
    "    print(\"각 마라톤 이벤트별 날씨 정보를 수집합니다 (필요시 API 호출)...\")\n",
    "    for index, row in unique_events.iterrows():\n",
    "        year_val = row[year_col]\n",
    "        dataset_id = row[dataset_col]\n",
    "        \n",
    "        if pd.isna(year_val): # 연도 값이 NaN이면 건너뛰기\n",
    "            print(f\"Skipping row with NaN year for dataset {dataset_id}\")\n",
    "            continue\n",
    "        \n",
    "        event_key = (dataset_id, int(year_val)) # 캐시 및 조회용 키\n",
    "\n",
    "        if event_key not in weather_data_cache: \n",
    "            if event_key in RACE_INFO_LOOKUP:\n",
    "                event_details = RACE_INFO_LOOKUP[event_key]\n",
    "                print(f\"  - {event_details['location_name']} {event_key[1]} ({event_details['date']}) 날씨 가져오는 중...\")\n",
    "                \n",
    "                avg_temp, avg_humidity = fetch_race_window_weather_for_event(\n",
    "                    event_details['lat'], \n",
    "                    event_details['lon'], \n",
    "                    event_details['date'],\n",
    "                    timezone=event_details.get('timezone', \"Etc/GMT\")\n",
    "                )\n",
    "                weather_data_cache[event_key] = (avg_temp, avg_humidity)\n",
    "                if avg_temp is not None and avg_humidity is not None:\n",
    "                    print(f\"    -> Fetched: Temp={avg_temp:.2f}°C, Humidity={avg_humidity:.2f}%\")\n",
    "                else:\n",
    "                    print(f\"    -> Failed to fetch full weather data for {event_details['location_name']} {event_key[1]}\")\n",
    "                time.sleep(0.5) \n",
    "            else:\n",
    "                print(f\"Warning: RACE_INFO_LOOKUP에 Dataset '{dataset_id}', Year '{event_key[1]}' 정보가 없습니다. 해당 이벤트 날씨는 Null 처리됩니다.\")\n",
    "                weather_data_cache[event_key] = (None, None) # 조회 실패 또는 정보 없음 명시\n",
    "        # else: # 캐시 사용 시 로그 (너무 길어질 수 있어 주석 처리)\n",
    "            # print(f\"  - Using cached weather for Dataset '{dataset_id}', Year '{event_key[1]}'.\")\n",
    "\n",
    "    # 날씨 정보를 DataFrame에 매핑\n",
    "    def apply_weather(row, val_idx):\n",
    "        if pd.isna(row[year_col]):\n",
    "            return None\n",
    "        lookup_key = (row[dataset_col], int(row[year_col]))\n",
    "        return weather_data_cache.get(lookup_key, (None, None))[val_idx]\n",
    "\n",
    "    df_to_process['temperature_race'] = df_to_process.apply(lambda row: apply_weather(row, 0), axis=1)\n",
    "    df_to_process['humidity_race'] = df_to_process.apply(lambda row: apply_weather(row, 1), axis=1)\n",
    "    \n",
    "    print(\"날씨 정보 병합 완료.\")\n",
    "    return df_to_process\n",
    "\n",
    "# --- 메인 실행 로직 ---\n",
    "if __name__ == '__main__':\n",
    "    # ==============================================================================\n",
    "    # ★★★ 1. 사용자 설정: 여기에 \"기존 통합 CSV 파일\" 경로와 컬럼명을 정확히 입력해주세요. ★★★\n",
    "    # ==============================================================================\n",
    "    # 이 파일은 보스턴, 모스크바, 시카고 등의 데이터가 이미 합쳐져 있고,\n",
    "    # 'Year'와 'Dataset' 컬럼을 포함하고 있어야 합니다.\n",
    "    EXISTING_COMBINED_CSV_FILE_PATH = \"./data/merged_marathon_data.csv\"  # <<< 경로를 실제 파일로 수정!!\n",
    "\n",
    "    YEAR_COLUMN_NAME_IN_CSV = 'Year'         # <<< 실제 'Year' 컬럼명으로 수정!!\n",
    "    DATASET_COLUMN_NAME_IN_CSV = 'Dataset'   # <<< 실제 'Dataset' 컬럼명('B', 'M', 'C' 등이 있는)으로 수정!!\n",
    "    \n",
    "    # 저장할 새로운 CSV 파일 경로 및 이름\n",
    "    OUTPUT_CSV_WITH_WEATHER_PATH = \"./data/combined_marathons_with_weather.csv\" # <<< 저장 경로 수정!!\n",
    "    # ==============================================================================\n",
    "\n",
    "    # 출력 디렉토리 생성 (필요한 경우)\n",
    "    output_dir = os.path.dirname(OUTPUT_CSV_WITH_WEATHER_PATH)\n",
    "    if output_dir and not os.path.exists(output_dir): # output_dir이 비어있지 않고 존재하지 않을 경우\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"출력 디렉토리 '{output_dir}'를 생성했습니다.\")\n",
    "\n",
    "    try:\n",
    "        print(f\"'{EXISTING_COMBINED_CSV_FILE_PATH}' 파일 로딩 중...\")\n",
    "        # CSV 로딩 시, 데이터 타입이 일관되도록 dtype 명시 고려 (특히 Year, Dataset)\n",
    "        df_combined_marathons = pd.read_csv(EXISTING_COMBINED_CSV_FILE_PATH, low_memory=False)\n",
    "        print(\"기존 통합 CSV 파일 로딩 완료.\")\n",
    "        print(\"\\n로딩된 데이터 정보 (상위 5행):\")\n",
    "        print(df_combined_marathons.head())\n",
    "        print(\"\\n로딩된 데이터 정보 (info):\")\n",
    "        df_combined_marathons.info()\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"FATAL Error: '{EXISTING_COMBINED_CSV_FILE_PATH}' 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
    "        exit()\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL Error: 기존 CSV 파일 로딩 중 오류 발생 - {e}\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n날씨 정보 통합 시작...\")\n",
    "    df_final_with_weather = add_weather_to_marathon_data(\n",
    "        df_combined_marathons, \n",
    "        year_col=YEAR_COLUMN_NAME_IN_CSV,      \n",
    "        dataset_col=DATASET_COLUMN_NAME_IN_CSV\n",
    "    )\n",
    "    \n",
    "    print(\"\\n최종 데이터프레임 정보 (날씨 통합 후, 상위 5행):\")\n",
    "    # 사용자가 보여준 예시 컬럼들을 포함하여 출력\n",
    "    cols_to_preview = ['Bib', 'Age_group', 'M/F', 'Country', '40K', 'Dataset', 'Year', 'temperature_race', 'humidity_race']\n",
    "    existing_preview_cols = [col for col in cols_to_preview if col in df_final_with_weather.columns]\n",
    "    print(df_final_with_weather[existing_preview_cols].head())\n",
    "    print(\"\\n최종 데이터프레임 정보 (info):\")\n",
    "    df_final_with_weather.info()\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(f\"\\n'{OUTPUT_CSV_WITH_WEATHER_PATH}' 파일로 저장 중...\")\n",
    "        df_final_with_weather.to_csv(OUTPUT_CSV_WITH_WEATHER_PATH, index=False, encoding='utf-8-sig')\n",
    "        print(f\"모든 정보가 포함된 최종 데이터가 '{OUTPUT_CSV_WITH_WEATHER_PATH}'에 성공적으로 저장되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: 최종 CSV 파일 저장 중 오류 발생 - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce8e85",
   "metadata": {},
   "source": [
    "# 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf37fb3",
   "metadata": {},
   "source": [
    "##### feature 설명\n",
    "- 'Bib':  단순 id / 동명이인 등을 구분하기 위함\n",
    "- 'Age_group' → 19: 19세 이하 / 70: 70세 이상 / 20~69세의 경우 → 29: 25~29세\n",
    "- ‘M/F’ → Man = 0 / Woman = 1 \n",
    "- 'Country' = 국적\n",
    "- '5p' → 출발로부터 5km까지 기준 pace[sec/km](sec)\n",
    "- '15p' → 10km부터 15km까지 기준 pace[sec/km](sec)\n",
    "- 'Final_Time’ → 풀코스(42.195km) 완주 기록(sec) \n",
    "- ‘Sub’ → sub-3,4,5,6,7을 숫자로만 표현 / 3 = 완주기록 3시간 미만(sec)\n",
    "- '5k' → 출발로부터 5km되었을때의 시간 기록(sec)\n",
    "- '15k' → 출발로부터 15km되었을때의 시간 기록(sec)\n",
    "- ‘Dataset’ → 사용 데이터셋 구분 [B: 보스턴 마라톤 / C: 시카고 / M: 모스크바]\n",
    "- ‘Year’ → 해당 데이터의 년도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b67330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 불러오기\n",
    "df = pd.read_csv('./real_final/FINAL_marathons_with_weather.csv')\n",
    "\n",
    "#5개 랜덤 샘플\n",
    "sample = df.sample(n=5, random_state=42)\n",
    "print(\"=== 5개 랜덤 샘플 ===\")\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "#결측치 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b61f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#기초 통계량 (count, mean, std, min, 25%, 50%, 75%, max)\n",
    "print(\"\\n=== 기초 통계량(summary) ===\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd8d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 피처·타깃 결측 확인 (optional)\n",
    "print(\"\\n=== 전체 데이터셋 결측 개수 ===\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7495ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 1) 보스턴 구간 경계점 고도 (m)\n",
    "boundary_alt = {\n",
    "    0.0: 149,\n",
    "    5.0:  72,\n",
    "    10.0: 55,\n",
    "    15.0: 46,\n",
    "    20.0: 46, #half\n",
    "    25.0: 40,\n",
    "    30.0: 18,\n",
    "    35.0: 40,\n",
    "    40.0: 18,\n",
    "}\n",
    "\n",
    "# 2) 5km 구간별 “순고도 변화(가중치)” 계산\n",
    "#    → boundary_alt 딕셔너리에서 바로 (end – (end – 5)) 로 계산\n",
    "seg_ends = [5.0, 10.0, 15.0, 20.0, 25.0, 30.0, 35.0, 40.0]\n",
    "seg_weights = {\n",
    "    end: boundary_alt[end] - boundary_alt[end - 5.0]\n",
    "    for end in seg_ends\n",
    "}\n",
    "\n",
    "# 3) 새로운 컬럼(wt_5K, wt_10K, …, wt_40K) 초기화 (0으로 채움)\n",
    "for end in seg_ends:\n",
    "    col_name = f\"wt_{int(end)}K\"\n",
    "    df[col_name] = 0.0\n",
    "\n",
    "# 4) “보스턴 데이터셋” 행(‘Dataset’ == 'B')에만 가중치 채워넣기\n",
    "mask_boston = (df[\"Dataset\"] == \"B\")\n",
    "for end, w in seg_weights.items():\n",
    "    col_name = f\"wt_{int(end)}K\"\n",
    "    # 보스턴 행에만 해당 세그먼트 가중치 w 할당\n",
    "    df.loc[mask_boston, col_name] = w\n",
    "\n",
    "# 5) 결과 확인\n",
    "#    - 보스턴 행에서 새로 생성된 wt_*K 컬럼들만 출력\n",
    "cols_to_show = [f\"wt_{int(e)}K\" for e in seg_ends]\n",
    "print(\"=== 보스턴 데이터셋의 wt_*K 컬럼값(상위 5개 행) ===\")\n",
    "print(df.loc[mask_boston, cols_to_show].head())\n",
    "\n",
    "# 6) 보스턴이 아닌(non-B) 행 중에서 5개 랜덤 샘플 출력 (확인용)\n",
    "non_b_sample = df[df[\"Dataset\"] != \"B\"].sample(n=5, random_state=42)\n",
    "print(\"\\n=== 보스턴 아닌 행에서 5개 랜덤 샘플 ===\")\n",
    "print(non_b_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# macOS 한글 폰트 설정\n",
    "mpl.rcParams['font.family'] = 'AppleGothic'\n",
    "# 마이너스 기호 깨짐 방지\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dff4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Sub(목표 그룹)별 전체 완주 페이스 비교\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(data=df, x='Sub', y=df['Final_Time'] / 42.195)\n",
    "plt.ylabel('평균 페이스 (sec/km)')\n",
    "plt.title('Sub 그룹별 평균 페이스 분포')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054fd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-2. Sub 그룹별 구간별 통과 시간 분포\n",
    "\n",
    "# 1) 필요한 컬럼만 melt\n",
    "segments = ['5K','10K','15K','Half','25K','30K','35K','40K']\n",
    "df_melt = df.melt(\n",
    "    id_vars='Sub',\n",
    "    value_vars=segments,\n",
    "    var_name='Segment',\n",
    "    value_name='Time'\n",
    ")\n",
    "\n",
    "# 2) Segment 순서 지정\n",
    "df_melt['Segment'] = pd.Categorical(\n",
    "    df_melt['Segment'],\n",
    "    categories=segments,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(\n",
    "    data=df_melt,\n",
    "    x='Segment', y='Time',\n",
    "    hue='Sub'\n",
    ")\n",
    "plt.title('Sub 그룹별 구간별 통과 시간 분포')\n",
    "plt.xlabel('구간 종단점 (km)')\n",
    "plt.ylabel('통과 시간 (sec)')\n",
    "plt.legend(title='Sub 그룹', bbox_to_anchor=(1.05,1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-1. 국가(Country)별 완주 기록 차이 (상위)\n",
    "top_countries = df['Country'].value_counts().index[:8]\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(data=df[df['Country'].isin(top_countries)],\n",
    "            x='Country', y='Final_Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('완주시간 (sec)')\n",
    "plt.title('상위 8개국 완주시간 분포')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a299bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-2. 국가(Country)별 완주 기록 차이 (상하위)\n",
    "# 1) 상위 8개국 / 하위 8개국 리스트 생성\n",
    "country_counts = df['Country'].value_counts()\n",
    "top8    = country_counts.index[:8]\n",
    "bottom8 = country_counts.index[-8:]\n",
    "\n",
    "# 2) 플롯 그리기\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5), sharey=True)\n",
    "\n",
    "# 상위 8개국\n",
    "sns.boxplot(\n",
    "    data=df[df['Country'].isin(top8)],\n",
    "    x='Country', y='Final_Time',\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('상위 8개국 완주시간 분포')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].set_ylabel('완주시간 (sec)')\n",
    "\n",
    "# 하위 8개국\n",
    "sns.boxplot(\n",
    "    data=df[df['Country'].isin(bottom8)],\n",
    "    x='Country', y='Final_Time',\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title('하위 8개국 완주시간 분포')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-3. 국가(Country)별 완주 기록 차이 (동양)\n",
    "# 1) 동양 국가 코드 리스트 정의\n",
    "eastern_countries = ['KOR', 'JPN', 'CHN', 'TPE', 'HKG']\n",
    "\n",
    "# 2) 동양 국가만 필터링\n",
    "df_east = df[df['Country'].isin(eastern_countries)].copy()\n",
    "\n",
    "# 3) 간단히 참가자 수 확인\n",
    "print(\"동양 국가별 참가자 수:\")\n",
    "print(df_east['Country'].value_counts())\n",
    "\n",
    "# 4) 완주시간 분포 박스플롯\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(data=df_east, x='Country', y='Final_Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('동양 국가별 완주시간 분포')\n",
    "plt.ylabel('완주시간 (sec)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d9a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-4. 국가(Country)별 완주 기록 차이 (상위, 하위, 동양 비교)\n",
    "# 1) 그룹별 국가 코드 정의\n",
    "country_counts = df['Country'].value_counts()\n",
    "top8    = set(country_counts.index[:8])\n",
    "bottom8 = set(country_counts.index[-8:])\n",
    "east_asia = {'KOR','JPN','CHN','TPE','HKG'}  # 필요시 더 추가\n",
    "\n",
    "# 2) 각 행에 group 라벨 할당\n",
    "def label_group(c):\n",
    "    if c in top8:\n",
    "        return 'Top'\n",
    "    if c in bottom8:\n",
    "        return 'Bottom'\n",
    "    if c in east_asia:\n",
    "        return 'East'\n",
    "    return None\n",
    "\n",
    "df['group'] = df['Country'].map(label_group)\n",
    "\n",
    "# 3) 관심 있는 세 그룹만 필터\n",
    "df3 = df[df['group'].notna()].copy()\n",
    "\n",
    "# 4) 기초통계: 평균·중앙값·표준편차\n",
    "stats = df3.groupby('group')['Final_Time'] \\\n",
    "           .agg(['count','mean','median','std']) \\\n",
    "           .rename(columns={'count':'n','mean':'mean(sec)','median':'median(sec)','std':'std(sec)'})\n",
    "print(\"=== 그룹별 완주시간 기초통계 ===\")\n",
    "print(stats)\n",
    "\n",
    "# 5) 박스플롯으로 분포 비교\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(data=df3, x='group', y='Final_Time',\n",
    "            order=['Top','Bottom','East'],\n",
    "            palette='pastel')\n",
    "plt.title('Top vs Bottom vs East: 완주시간 분포')\n",
    "plt.xlabel('그룹')\n",
    "plt.ylabel('완주시간 (sec)')\n",
    "plt.show()\n",
    "\n",
    "# 6) 평균·중앙값 막대그래프\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=stats.index, y=stats['mean(sec)'], order=['Top','Bottom','East'])\n",
    "for i, v in enumerate(stats['mean(sec)']):\n",
    "    plt.text(i, v+50, f\"{v:.0f}\", ha='center')\n",
    "plt.title('그룹별 평균 완주시간')\n",
    "plt.ylabel('평균 완주시간 (sec)')\n",
    "plt.xlabel('그룹')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. 성별・연령대별 완주 페이스\n",
    "\n",
    "# 1) Final_Time을 시간, 분 단위로 추가\n",
    "df['Finish_Hours'] = df['Final_Time'] / 3600       # 시간 단위\n",
    "df['Finish_Minutes'] = df['Final_Time'] / 60       # 분 단위\n",
    "\n",
    "# ——— (A) 성별에 따른 완주시간 분포 ———\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.boxplot(data=df, x='M/F', y='Finish_Hours')\n",
    "plt.xticks([0,1], ['남','여'])\n",
    "plt.ylabel('완주시간 (시간)')\n",
    "plt.title('성별에 따른 완주시간 분포')\n",
    "plt.show()\n",
    "\n",
    "# ——— (B) 연령대에 따른 완주시간 분포 ———\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(data=df, x='Age_group', y='Finish_Hours')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('완주시간 (시간)')\n",
    "plt.title('연령대별 완주시간 분포')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#4-1. 성별 , 연령별 페이스 분석 advance\n",
    "\n",
    "# 1) 구간별 페이스 컬럼 목록\n",
    "pace_cols = [\"5p\", \"10p\", \"15p\", \"Halfp\", \"25p\", \"30p\", \"35p\", \"40p\"]\n",
    "\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "# 2) Boxplot: “연령대 × 성별” 구간별 페이스 분산 비교\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "\n",
    "# 2-1) 데이터 긴 형태(Long Format)로 변환\n",
    "df_long = df.melt(\n",
    "    id_vars=[\"Age_group\", \"M/F\"],\n",
    "    value_vars=pace_cols,\n",
    "    var_name=\"Segment\",\n",
    "    value_name=\"Pace\"\n",
    ")\n",
    "\n",
    "# 2-2) 예시: 40p 구간 “연령대별·성별 Boxplot”\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    data=df_long[df_long[\"Segment\"] == \"40p\"],\n",
    "    x=\"Age_group\",\n",
    "    y=\"Pace\",\n",
    "    hue=\"M/F\",\n",
    "    palette=[\"skyblue\", \"lightpink\"]\n",
    ")\n",
    "plt.title(\"40p 구간 페이스 분포: 연령대별·성별 Boxplot\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Pace (sec)\")\n",
    "plt.legend(title=\"Gender (0=Male, 1=Female)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2-3) 모든 구간을 한 번에 보고 싶다면 FacetGrid 사용 (옵션)\n",
    "g = sns.FacetGrid(\n",
    "    df_long, \n",
    "    row=\"Segment\", \n",
    "    col=\"M/F\", \n",
    "    sharex=False, \n",
    "    sharey=False, \n",
    "    height=2.5, \n",
    "    aspect=2\n",
    ")\n",
    "g.map_dataframe(sns.boxplot, x=\"Age_group\", y=\"Pace\", palette=\"pastel\")\n",
    "g.set_axis_labels(\"Age Group\", \"Pace (sec)\")\n",
    "g.set_titles(row_template=\"{row_name}\", col_template=\"Gender {col_name}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2-4) 연령대·성별 구간별 표준편차 계산 & print\n",
    "std_table = df_long.groupby([\"Segment\", \"Age_group\", \"M/F\"])[\"Pace\"].std().unstack().fillna(0)\n",
    "print(\"\\n=== Segment × Age_group × Gender (std of Pace) ===\")\n",
    "print(std_table)\n",
    "\n",
    "\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "# 3) 통계적 유의성 검정: “각 연령대별” 남녀 간 페이스 차이 (t-test)\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "ttest_results = []\n",
    "for seg in pace_cols:\n",
    "    for age in sorted(df[\"Age_group\"].unique()):\n",
    "        male_vals = df[(df[\"M/F\"] == 0) & (df[\"Age_group\"] == age)][seg].dropna()\n",
    "        female_vals = df[(df[\"M/F\"] == 1) & (df[\"Age_group\"] == age)][seg].dropna()\n",
    "        # 최소 각 그룹 샘플 수 5개 이상 있어야 검정 가능\n",
    "        if len(male_vals) >= 5 and len(female_vals) >= 5:\n",
    "            tstat, pval = ttest_ind(male_vals, female_vals, equal_var=False)\n",
    "            significant = (pval < 0.05)\n",
    "            ttest_results.append({\n",
    "                \"Segment\": seg,\n",
    "                \"Age_group\": age,\n",
    "                \"p-value\": pval,\n",
    "                \"Significant\": significant\n",
    "            })\n",
    "        else:\n",
    "            ttest_results.append({\n",
    "                \"Segment\": seg,\n",
    "                \"Age_group\": age,\n",
    "                \"p-value\": np.nan,\n",
    "                \"Significant\": False\n",
    "            })\n",
    "\n",
    "ttest_df = pd.DataFrame(ttest_results)\n",
    "# 피벗 테이블 형태로 표시: index=Age_group, columns=Segment, 값은 “유의미 여부”\n",
    "pivot_signif = ttest_df.pivot(\n",
    "    index=\"Age_group\",\n",
    "    columns=\"Segment\",\n",
    "    values=\"Significant\"\n",
    ")\n",
    "print(\"\\n=== Segment × Age_group t-test (Male vs Female) – Significant 여부 ===\")\n",
    "print(pivot_signif)\n",
    "\n",
    "\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "# 4) 회귀분석: “Age_group × 성별 상호작용” 검정 (예시: 40p 구간)\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "df_reg = df.dropna(subset=[\"Age_group\", \"M/F\", \"40p\"]).copy()\n",
    "\n",
    "# OLS 회귀 모델: 40p ~ Age_group * (M/F)\n",
    "model = smf.ols(\"Q('40p') ~ Age_group * Q('M/F')\", data=df_reg).fit()\n",
    "\n",
    "# 회귀 결과를 텍스트로 출력 (lxml 없이 가능)\n",
    "print(\"\\n=== Regression Summary: 40p Pace ~ Age_group * Gender ===\")\n",
    "print(model.summary())\n",
    "\n",
    "# (원한다면 아래처럼 계수만 별도 출력 가능)\n",
    "print(\"\\n=== Coefficients ===\")\n",
    "print(model.params)\n",
    "print(\"\\n=== p-values ===\")\n",
    "print(model.pvalues)\n",
    "\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "# 5) 정규화된 페이스 지표 생성 & 분석\n",
    "#    - 세그먼트당 평균 페이스 = Final_Time / 8\n",
    "#    - 정규화된 페이스 = 세그먼트 페이스 / (Final_Time/8)\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "df_norm = df.dropna(subset=pace_cols + [\"Final_Time\"]).copy()\n",
    "df_norm[\"Avg_per_segment\"] = df_norm[\"Final_Time\"] / 8\n",
    "\n",
    "for seg in pace_cols:\n",
    "    df_norm[f\"{seg}_norm\"] = df_norm[seg] / df_norm[\"Avg_per_segment\"]\n",
    "\n",
    "# 5-1) 40p_norm에 대한 연령대·성별 Boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    data=df_norm,\n",
    "    x=\"Age_group\",\n",
    "    y=\"40p_norm\",\n",
    "    hue=\"M/F\",\n",
    "    palette=[\"skyblue\", \"lightpink\"]\n",
    ")\n",
    "plt.title(\"40p Normalized Pace (seg pace / avg pace) by Age_group & Gender\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Normalized 40p Pace\")\n",
    "plt.legend(title=\"Gender\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5-2) 연령대×성별별 정규화된 페이스 평균 출력\n",
    "norm_table = df_norm.groupby([\"Age_group\", \"M/F\"])[[f\"{seg}_norm\" for seg in pace_cols]].mean()\n",
    "print(\"\\n=== Normalized Pace by Age_group × Gender ===\")\n",
    "print(norm_table)\n",
    "\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "# 6) 클러스터별(실력별) 연령·성별 패턴 비교\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "df_cluster = df.dropna(subset=pace_cols + [\"Final_Time\", \"Age_group\", \"M/F\"]).copy()\n",
    "X = df_cluster[pace_cols].values\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_cluster[\"pace_cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "# 클러스터별 Age_group 분포 & Gender 분포 출력\n",
    "cluster_age_dist = df_cluster.groupby([\"pace_cluster\", \"Age_group\"])[\"pace_cluster\"].count().unstack(fill_value=0)\n",
    "cluster_gender_dist = df_cluster.groupby([\"pace_cluster\", \"M/F\"])[\"pace_cluster\"].count().unstack(fill_value=0)\n",
    "\n",
    "print(\"\\n=== Cluster × Age_group Distribution ===\")\n",
    "print(cluster_age_dist)\n",
    "print(\"\\n=== Cluster × Gender Distribution ===\")\n",
    "print(cluster_gender_dist)\n",
    "\n",
    "# 클러스터별 평균 패턴 시각화\n",
    "cluster_centers = pd.DataFrame(kmeans.cluster_centers_, columns=pace_cols)\n",
    "cluster_centers[\"cluster\"] = cluster_centers.index\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, row in cluster_centers.iterrows():\n",
    "    plt.plot(\n",
    "        pace_cols,\n",
    "        row[pace_cols],\n",
    "        marker=\"o\",\n",
    "        linewidth=2,\n",
    "        label=f\"Cluster {int(row['cluster'])}\"\n",
    "    )\n",
    "plt.title(\"클러스터별 평균 구간 페이스 패턴\")\n",
    "plt.xlabel(\"Segment\")\n",
    "plt.ylabel(\"Pace (sec)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 클러스터별 성별 비율 (정규화된 막대그래프)\n",
    "cluster_gender_dist_norm = cluster_gender_dist.div(cluster_gender_dist.sum(axis=1), axis=0)\n",
    "plt.figure(figsize=(8, 4))\n",
    "cluster_gender_dist_norm.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    color=[\"skyblue\", \"lightpink\"]\n",
    ")\n",
    "plt.title(\"클러스터별 Gender 비율 (Normalized)\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.legend(title=\"Gender\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 클러스터별 연령대 비율 (정규화된 막대그래프)\n",
    "cluster_age_dist_norm = cluster_age_dist.div(cluster_age_dist.sum(axis=1), axis=0)\n",
    "plt.figure(figsize=(10, 6))\n",
    "cluster_age_dist_norm.plot(kind=\"bar\", stacked=True, colormap=\"tab20\")\n",
    "plt.title(\"클러스터별 Age Group 비율 (Normalized)\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. 환경 변수(온도, 습도) vs 페이스 상관\n",
    "\n",
    "#1) 상관계수 계산\n",
    "corr_cols = [\"temperature_race\", \"humidity_race\", \"5p\", \"10p\", \"15p\", \"Halfp\", \"25p\", \"30p\", \"35p\", \"40p\"]\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "print(\"\\n== 날씨·환경 vs 구간별 페이스 상관계수 ==\")\n",
    "print(corr_matrix.loc[[\"temperature_race\", \"humidity_race\"], [\"5p\", \"10p\", \"15p\", \"Halfp\", \"25p\", \"30p\", \"35p\", \"40p\"]])\n",
    "\n",
    "\n",
    "\n",
    "# 2) 상관관계를 보고 싶은 컬럼들\n",
    "corr_cols = [\n",
    "    \"temperature_race\", \"humidity_race\",\n",
    "    \"5p\", \"10p\", \"15p\", \"Halfp\", \"25p\", \"30p\", \"35p\", \"40p\",\n",
    "    \"Final_Time\"\n",
    "]\n",
    "\n",
    "# 3) 상관계수 계산\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "\n",
    "# 4) 히트맵 시각화\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,        # 셀에 숫자 표시\n",
    "    fmt=\".2f\",         # 소수점 둘째 자리까지 표시\n",
    "    cmap=\"coolwarm\",   # 컬러맵 지정\n",
    "    vmin=-1, vmax=1,   # 상관계수 범위\n",
    "    linewidths=0.5,    # 셀 사이 경계선 두께\n",
    "    linecolor=\"white\"  # 셀 경계선 색상\n",
    ")\n",
    "plt.title(\"날씨(온도·습도) vs 구간별 페이스 & 완주 시간 상관계수\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5) 산점도 + 회귀선 (기온 vs 완주 시간)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.regplot(\n",
    "    data=df,\n",
    "    x=\"temperature_race\",\n",
    "    y=\"Final_Time\",\n",
    "    scatter_kws={\"s\": 15, \"alpha\": 0.3},\n",
    "    line_kws={\"color\": \"red\"}\n",
    ")\n",
    "plt.title(\"기온 vs 완주 시간 상관관계\")\n",
    "plt.xlabel(\"temperature_race (℃)\")\n",
    "plt.ylabel(\"Final_Time (초)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6) 산점도 + 회귀선 (습도 vs 완주 시간)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.regplot(\n",
    "    data=df,\n",
    "    x=\"humidity_race\",\n",
    "    y=\"Final_Time\",\n",
    "    scatter_kws={\"s\": 15, \"alpha\": 0.3},\n",
    "    line_kws={\"color\": \"blue\"}\n",
    ")\n",
    "plt.title(\"습도 vs 완주 시간 상관관계\")\n",
    "plt.xlabel(\"humidity_race (%)\")\n",
    "plt.ylabel(\"Final_Time (초)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35799d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-1. 환경 변수(온도, 습도) vs 페이스 상관 advance\n",
    "#비슷한 실력군으로 제한\n",
    "\n",
    "race_list = df[\"Dataset\"].unique()\n",
    "\n",
    "\n",
    "# 1) 엘리트 그룹(Sub < 8000초) 분석\n",
    "# -----------------------------------\n",
    "elite_df = df[df[\"Sub\"] < 8000].copy()\n",
    "if not elite_df.empty:\n",
    "    print(\"\\n=== 엘리트 그룹(Sub < 8000) 전체: 온도·습도 vs Final_Time 상관계수 ===\")\n",
    "    corr_cols_elite = [\"temperature_race\", \"humidity_race\", \"Final_Time\"]\n",
    "    corr_matrix_elite = elite_df[corr_cols_elite].corr()\n",
    "    print(corr_matrix_elite.loc[[\"temperature_race\", \"humidity_race\"], [\"Final_Time\"]])\n",
    "\n",
    "    # (1) 기온 vs 완주 시간 (엘리트)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.regplot(\n",
    "        data=elite_df,\n",
    "        x=\"temperature_race\",\n",
    "        y=\"Final_Time\",\n",
    "        scatter_kws={\"s\": 20, \"alpha\": 0.4, \"color\": \"darkred\"},\n",
    "        line_kws={\"color\": \"orange\", \"linewidth\": 2}\n",
    "    )\n",
    "    plt.title(\"엘리트 그룹: 기온 vs 완주 시간\")\n",
    "    plt.xlabel(\"temperature_race (℃)\")\n",
    "    plt.ylabel(\"Final_Time (초)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # (2) 습도 vs 완주 시간 (엘리트)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.regplot(\n",
    "        data=elite_df,\n",
    "        x=\"humidity_race\",\n",
    "        y=\"Final_Time\",\n",
    "        scatter_kws={\"s\": 20, \"alpha\": 0.4, \"color\": \"darkblue\"},\n",
    "        line_kws={\"color\": \"skyblue\", \"linewidth\": 2}\n",
    "    )\n",
    "    plt.title(\"엘리트 그룹: 습도 vs 완주 시간\")\n",
    "    plt.xlabel(\"humidity_race (%)\")\n",
    "    plt.ylabel(\"Final_Time (초)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"엘리트 그룹(Sub < 8000) 데이터가 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f64f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-1 도시(Dataset)별 평균 페이스 비교 (예: Boston vs 나머지)\n",
    "city_stats = df.groupby(\"Dataset\")[[\"5p\", \"40p\"]].mean().reset_index()\n",
    "print(\"\\n== Dataset별(도시별) 5p & 40p 평균 페이스 ==\")\n",
    "print(city_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c50ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. 전체 수치형 Feature 상관관계 히트맵\n",
    "num_cols = ['Final_Time', 'temperature_race','humidity_race'] + pace_cols\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(df[num_cols].corr(), annot=True, fmt=\".2f\", cmap='vlag')\n",
    "plt.title('수치형 변수 상관관계')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e633acc0",
   "metadata": {},
   "source": [
    "1. 구간별 Pace 상관관계\n",
    "\n",
    "5p,10p,…,40p (혹은 pace_*로 재계산했다면 그 값들) 가 서로 0.86~0.99 사이의 매우 높은 상관을 보입니다.\n",
    "\n",
    "즉, 초반 페이스가 빠르면 거의 끝까지 일관되게 빠른 경향이 있습니다.\n",
    "\n",
    "2. Final_Time vs Pace\n",
    "\n",
    "모든 구간 Pace와 Final_Time(풀코스 총 완주 시간)은 0.89~0.98 의 매우 강한 양(+)의 상관을 가집니다.\n",
    "\n",
    "전체 완주 시간은 곧 5km 구간 페이스들의 합(또는 평균)이므로 당연히 높게 나옵니다.\n",
    "\n",
    "3. 온도·습도 영향\n",
    "\n",
    "temperature_race 와 Final_Time 은 약 –0.09 (약한 음의 상관),\n",
    "\n",
    "humidity_race 와 Final_Time 은 약 –0.07 로,\n",
    "\n",
    "두 환경 변수는 페이스와도 거의 상관이 없습니다.\n",
    "\n",
    "다만 온도와 습도끼리는 –0.97 로 매우 강한 음(–)의 상관을 보이는데, 이는 데이터 수집 환경(높은 온도일수록 상대습도가 낮게 기록됨)을 반영하는 듯합니다.\n",
    "\n",
    "결론: 이 데이터에선 “누가 빠른지”는 전 구간 페이스가 강하게 묶여 있고, 환경 요인(온도·습도)은 페이스나 완주 시간에 미미한 영향만 줍니다.\n",
    "따라서 모델에 넣을 때는 구간별 pace 와 Final_Time 은 중복 정보이니 하나만 쓰거나, PCA 등으로 차원 축소를 고려하는 게 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5151651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "#8 구간 간 페이스 변화 패턴 탐색\n",
    "\n",
    "# 구간별 페이스 컬럼 목록\n",
    "pace_cols = [\"5p\", \"10p\", \"15p\", \"Halfp\", \"25p\", \"30p\", \"35p\", \"40p\"]\n",
    "\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "# 2) 페이스(속도) 분포 살펴보기\n",
    "#    • 전체 구간별 히스토그램 + KDE\n",
    "#    • 구간별 Boxplot, Violin Plot\n",
    "#    → “구간이 진행될수록 평균·분산이 바뀐다” 증명\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "\n",
    "# 2.1 히스토그램 + KDE (5p ~ 40p)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, col in zip(axes, pace_cols):\n",
    "    sns.histplot(\n",
    "        data=df[col].dropna(),\n",
    "        kde=True,\n",
    "        bins=30,\n",
    "        color=\"skyblue\",\n",
    "        edgecolor=\"white\",\n",
    "        alpha=0.7,\n",
    "        ax=ax\n",
    "    )\n",
    "    mean_val = df[col].mean()\n",
    "    std_val = df[col].std()\n",
    "    ax.axvline(mean_val, color=\"red\", linestyle=\"--\", label=f\"Mean: {mean_val:.1f}\")\n",
    "    ax.axvline(mean_val + std_val, color=\"gray\", linestyle=\":\", label=\"+1σ\")\n",
    "    ax.axvline(mean_val - std_val, color=\"gray\", linestyle=\":\", label=\"-1σ\")\n",
    "    ax.set_title(f\"{col} 페이스 분포\")\n",
    "    ax.set_xlabel(\"페이스 (초)\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend(loc=\"upper right\", fontsize=\"small\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2.2 Boxplot & Violin Plot (모든 구간을 한 번에 비교)\n",
    "#     데이터프레임을 “긴 형태(long form)”으로 변환\n",
    "# Boxplot과 Violin Plot을 한 화면(2행 1열)으로 배치\n",
    "df_long = df.melt(id_vars=[], value_vars=pace_cols, var_name=\"Segment\", value_name=\"Pace\")\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 10))\n",
    "\n",
    "# (1) Boxplot\n",
    "sns.boxplot(\n",
    "    data=df_long,\n",
    "    x=\"Segment\", y=\"Pace\",\n",
    "    palette=\"pastel\",\n",
    "    order=pace_cols,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"구간별 페이스 분포 (Boxplot)\")\n",
    "axes[0].set_xlabel(\"\")\n",
    "axes[0].set_ylabel(\"페이스 (초)\")\n",
    "\n",
    "# (2) Violin Plot\n",
    "sns.violinplot(\n",
    "    data=df_long,\n",
    "    x=\"Segment\", y=\"Pace\",\n",
    "    inner=\"quartile\",\n",
    "    palette=\"muted\",\n",
    "    order=pace_cols,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"구간별 페이스 분포 (Violin Plot)\")\n",
    "axes[1].set_xlabel(\"구간\")\n",
    "axes[1].set_ylabel(\"페이스 (초)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "# 3) 구간 간 페이스 변화 패턴 탐색\n",
    "#    • 3.1) 대표 샘플 10명 꺾은선 그래프\n",
    "#    • 3.2) KMeans 클러스터링 → 클러스터별 평균 페이스곡선 + 완주시간 비교\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "\n",
    "# 3.1 대표 샘플 10명 (결측치 없는 러너 중 랜덤 선택)\n",
    "sample_runners = df.dropna(subset=pace_cols).sample(n=10, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for _, row in sample_runners.iterrows():\n",
    "    pace_values = row[pace_cols].values.astype(float)\n",
    "    plt.plot(\n",
    "        pace_cols,\n",
    "        pace_values,\n",
    "        marker=\"o\",\n",
    "        alpha=0.7,\n",
    "        linewidth=1.5\n",
    "    )\n",
    "plt.title(\"대표 러너 10명의 구간별 페이스 변화 (선 그래프)\")\n",
    "plt.xlabel(\"구간\")\n",
    "plt.ylabel(\"페이스 (초)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3.2 클러스터링 (KMeans)\n",
    "# ——————————————————————————————————————————————————————————————\n",
    "# ① 클러스터링용 데이터: 결측치 제거 후 구간별 페이스 데이터만 사용\n",
    "df_cluster = df.dropna(subset=pace_cols).copy()\n",
    "X = df_cluster[pace_cols].values  # (N, 8) 행렬\n",
    "\n",
    "# ② KMeans 모델 학습 (클러스터 개수는 상황에 맞춰 조정 가능)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_cluster[\"pace_cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "# ③ 클러스터별 평균 구간 페이스(centroid) 추출\n",
    "cluster_centers = pd.DataFrame(\n",
    "    kmeans.cluster_centers_,\n",
    "    columns=pace_cols\n",
    ")\n",
    "cluster_centers[\"cluster\"] = cluster_centers.index\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, row in cluster_centers.iterrows():\n",
    "    plt.plot(\n",
    "        pace_cols,\n",
    "        row[pace_cols],\n",
    "        marker=\"o\",\n",
    "        linewidth=2,\n",
    "        label=f\"Cluster {int(row['cluster'])}\"\n",
    "    )\n",
    "plt.title(\"클러스터별 평균 구간 페이스 패턴\")\n",
    "plt.xlabel(\"구간\")\n",
    "plt.ylabel(\"평균 페이스 (초)\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ④ 클러스터별 완주시간 통계 비교\n",
    "cluster_stats = df_cluster.groupby(\"pace_cluster\")[\"Final_Time\"].agg(\n",
    "    mean_time=\"mean\",\n",
    "    median_time=\"median\",\n",
    "    count=\"count\"\n",
    ").reset_index()\n",
    "print(\"=== 클러스터별 완주시간 통계 ===\")\n",
    "print(cluster_stats)\n",
    "\n",
    "# 클러스터별 평균 완주시간 막대그래프\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(\n",
    "    data=cluster_stats,\n",
    "    x=\"pace_cluster\",\n",
    "    y=\"mean_time\",\n",
    "    palette=\"pastel\"\n",
    ")\n",
    "for idx, val in enumerate(cluster_stats[\"mean_time\"]):\n",
    "    plt.text(idx, val + 50, f\"{val:.0f}\", ha=\"center\")\n",
    "plt.title(\"클러스터별 평균 완주시간\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"평균 완주 시간 (초)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c064255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# 1) Sub-3 검증 데이터 확보 (예: Sub == 3)\n",
    "df_sub3 = df[df['Sub'] == 3].reset_index(drop=True)\n",
    "\n",
    "# 2) 특성 및 타깃 정의\n",
    "#   X: 신체정보, 목표그룹(Sub), 환경요인, 보스턴 고도 가중치(wt_*)\n",
    "feature_cols = [\n",
    "    'M/F',          # 성별 (0=남,1=여)\n",
    "    'Age_group',    # 연령대\n",
    "    'Sub',          # 목표 그룹\n",
    "    'temperature_race',\n",
    "    'humidity_race',\n",
    "    # 보스턴만 값이 들어있는 wt_컬럼 (없으면 NaN→0 처리 필요)\n",
    "    'wt_5K', 'wt_10K', 'wt_15K', 'wt_20K',\n",
    "    'wt_25K', 'wt_30K', 'wt_35K', 'wt_40K'\n",
    "]\n",
    "\n",
    "#   Y: 5km 구간별 페이스(초/km)\n",
    "target_cols = ['5p','10p','15p','Halfp','25p','30p','35p','40p']\n",
    "\n",
    "#-------------------------------------------\n",
    "\n",
    "X = df_sub3[feature_cols].fillna(0)   # NaN 이 있으면 0 으로 대체\n",
    "Y = df_sub3[target_cols].fillna(0)\n",
    "\n",
    "# 3) 학습/검증 분할\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 4) 파이프라인 구성 (스케일링 + 다중출력 회귀)\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', MultiOutputRegressor(\n",
    "        RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 5) 학습\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# 6) 검증\n",
    "Y_pred = pipeline.predict(X_val)\n",
    "\n",
    "print(\"=== 구간별 MAE & R² ===\")\n",
    "for i, col in enumerate(target_cols):\n",
    "    mae = mean_absolute_error(Y_val.iloc[:, i], Y_pred[:, i])\n",
    "    r2  = r2_score(Y_val.iloc[:, i],    Y_pred[:, i])\n",
    "    print(f\"{col}: MAE={mae:.2f} sec/km,  R²={r2:.3f}\")\n",
    "\n",
    "# 7) 예측 예시: 30세 남성, Sub-3, 10℃·80% 습도, 보스턴 고도 가중치 적용\n",
    "example = pd.DataFrame([{\n",
    "    'M/F': 0,\n",
    "    'Age_group': 30,\n",
    "    'Sub': 3,\n",
    "    'temperature_race': 10,\n",
    "    'humidity_race': 80,\n",
    "    'wt_5K':  -77,\n",
    "    'wt_10K': -17,\n",
    "    'wt_15K':  -9,\n",
    "    'wt_20K':   0,\n",
    "    'wt_25K': -6,\n",
    "    'wt_30K': -22,\n",
    "    'wt_35K': +22,\n",
    "    'wt_40K': -22\n",
    "}])\n",
    "pred = pipeline.predict(example)\n",
    "print(\"\\n예측된 구간별 페이스(sec/km):\")\n",
    "print(dict(zip(target_cols, pred[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f756e",
   "metadata": {},
   "source": [
    "# 학습을 위한 데이터셋 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_age_group(age_group_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"'Age_group' 문자열을 대표 숫자 나이로 변환합니다.\"\"\"\n",
    "    def convert_age(ag_str):\n",
    "        ag_str = str(ag_str).strip() # 문자열로 변환하고 공백 제거\n",
    "        if ag_str == '19': # 19세 이하\n",
    "            return 18 # 또는 19\n",
    "        elif ag_str == '70': # 70세 이상\n",
    "            return 72 # 또는 70\n",
    "        elif len(ag_str) == 2 and ag_str.isdigit(): # 예: '29' (25-29세), '34' (30-34세)\n",
    "            upper_bound = int(ag_str)\n",
    "            lower_bound = upper_bound - 4\n",
    "            return (lower_bound + upper_bound) / 2\n",
    "        else:\n",
    "            return np.nan # 그 외 알 수 없는 값\n",
    "    return age_group_series.apply(convert_age)\n",
    "\n",
    "def prepare_model_ready_data(input_csv_path: str, output_csv_path: str):\n",
    "    \"\"\"\n",
    "    FINAL_marathons_with_weather.csv 파일을 읽어 모델 학습에 필요한\n",
    "    최종 특성 및 목표 변수를 만들고 정제하여 새 CSV로 저장합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"'{input_csv_path}' 파일 로딩 중...\")\n",
    "        df = pd.read_csv(input_csv_path, low_memory=False)\n",
    "        print(\"파일 로딩 완료.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"FATAL Error: 입력 파일 '{input_csv_path}'을(를) 찾을 수 없습니다.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL Error: 파일 로딩 중 오류 발생 - {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 1. Age_group 처리 ---\n",
    "    if 'Age_group' in df.columns:\n",
    "        df['age_numeric'] = preprocess_age_group(df['Age_group'])\n",
    "        print(\"'Age_group'을 'age_numeric'으로 변환 완료.\")\n",
    "    else:\n",
    "        print(\"Warning: 'Age_group' 컬럼이 없습니다.\")\n",
    "        df['age_numeric'] = np.nan # 컬럼이 없으면 NaN으로 생성\n",
    "\n",
    "    # --- 2. 목표 변수 (구간별 페이스) 정의 및 생성 ---\n",
    "    # 기존 Xp 컬럼들을 목표 변수로 사용하고, 이름 변경\n",
    "    # (5p, 10p, 15p, Halfp, 25p, 30p, 35p, 40p 순서로 가정)\n",
    "    # Halfp는 어느 구간인지 명확한 정의가 필요하나, 일단 그대로 사용\n",
    "    pace_target_cols_original = ['5p', '10p', '15p', 'Halfp', '25p', '30p', '35p', '40p']\n",
    "    pace_target_cols_new = [\n",
    "        'target_pace_0_5km', 'target_pace_5_10km', 'target_pace_10_15km', \n",
    "        'target_pace_15_Half', \n",
    "        'target_pace_Half_25km',\n",
    "        'target_pace_25_30km', 'target_pace_30_35km', 'target_pace_35_40km'\n",
    "    ]\n",
    "\n",
    "    # 실제 존재하는 컬럼만 이름 변경 시도\n",
    "    rename_dict = {}\n",
    "    for old, new in zip(pace_target_cols_original, pace_target_cols_new):\n",
    "        if old in df.columns:\n",
    "            rename_dict[old] = new\n",
    "        else:\n",
    "            print(f\"Warning: 목표 변수용 페이스 컬럼 '{old}'가 원본 데이터에 없습니다. 해당 목표 변수는 생성되지 않습니다.\")\n",
    "    df.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    # 마지막 구간 (40km ~ 완주) 페이스 계산\n",
    "    # 풀코스 거리 정의 (km)\n",
    "    FULL_MARATHON_DISTANCE_KM = 42.195 \n",
    "    if 'Final_Time' in df.columns and '40K' in df.columns:\n",
    "        # 40km 이후 남은 거리 (km)\n",
    "        remaining_distance_km = FULL_MARATHON_DISTANCE_KM - 40.0\n",
    "        # 40km 이후 걸린 시간 (sec)\n",
    "        time_after_40k_sec = df['Final_Time'] - df['40K']\n",
    "        # 40km 이후 페이스 (sec/km)\n",
    "        # 남은 거리가 0보다 크고, 시간도 양수인 경우에만 계산\n",
    "        df['target_pace_40_finish'] = np.where(\n",
    "            (remaining_distance_km > 0) & (time_after_40k_sec >= 0) & (df['40K'] <= df['Final_Time']),\n",
    "            time_after_40k_sec / remaining_distance_km,\n",
    "            np.nan\n",
    "        )\n",
    "        pace_target_cols_new.append('target_pace_40_finish')\n",
    "        print(\"마지막 구간(40km-완주) 페이스 계산 완료.\")\n",
    "    else:\n",
    "        print(\"Warning: 'Final_Time' 또는 '40K' 컬럼이 없어 마지막 구간 페이스를 계산할 수 없습니다.\")\n",
    "\n",
    "    # 생성된 실제 목표 변수 컬럼 목록\n",
    "    final_pace_target_columns = [col for col in pace_target_cols_new if col in df.columns]\n",
    "    if not final_pace_target_columns:\n",
    "        print(\"Error: 생성된 목표 페이스 변수가 하나도 없습니다. Xp 또는 XK 컬럼명을 확인해주세요.\")\n",
    "\n",
    "\n",
    "    # --- 3. 입력 특성(X) 선택 및 가공 ---\n",
    "    # 사용자 입력 플레이스홀더 추가 (모델 학습 시에는 NaN 또는 특정값으로, 예측 시에는 사용자 입력 사용)\n",
    "    df['user_weekly_km'] = np.nan # 사용자가 입력할 주간 평균 달리기 거리\n",
    "    df['user_target_time_sec'] = np.nan # 사용자가 입력할 목표 완주 시간 (초)\n",
    "\n",
    "    feature_columns = [\n",
    "        'age_numeric', \n",
    "        'M/F', # 이미 0/1로 인코딩 되어있다고 가정\n",
    "        'Dataset', # 범주형 -> 원-핫 인코딩 필요\n",
    "        'Year', \n",
    "        'temperature_race', \n",
    "        'humidity_race',\n",
    "        'Sub', # 범주형 -> 원-핫 인코딩 필요\n",
    "        'user_weekly_km',\n",
    "        'user_target_time_sec'\n",
    "    ]\n",
    "    \n",
    "    # 실제 존재하는 특성 컬럼만 선택\n",
    "    existing_feature_columns = [col for col in feature_columns if col in df.columns]\n",
    "    if len(existing_feature_columns) != len(feature_columns):\n",
    "        print(f\"Warning: 일부 기본 특성 컬럼이 원본 데이터에 없습니다. 있는 컬럼만 사용합니다: {existing_feature_columns}\")\n",
    "\n",
    "    # 최종 사용할 특성과 목표 변수만 선택\n",
    "    df_model_ready = df[existing_feature_columns + final_pace_target_columns].copy()\n",
    "\n",
    "    # 범주형 변수 원-핫 인코딩 (Dataset, Sub)\n",
    "    categorical_cols = []\n",
    "    if 'Dataset' in df_model_ready.columns: categorical_cols.append('Dataset')\n",
    "    if 'Sub' in df_model_ready.columns: categorical_cols.append('Sub')\n",
    "    \n",
    "    if categorical_cols:\n",
    "        df_model_ready = pd.get_dummies(df_model_ready, columns=categorical_cols, dummy_na=False) # dummy_na=False: NaN에 대한 더미 변수 생성 안함\n",
    "        print(f\"범주형 변수 {categorical_cols} 원-핫 인코딩 완료.\")\n",
    "    \n",
    "    # --- 4. 결측치 처리 ---\n",
    "    # 목표 변수에 결측치가 있는 행은 예측/학습이 불가능하므로 우선 제거 (또는 다른 정교한 처리)\n",
    "    if final_pace_target_columns:\n",
    "        # 모든 목표 페이스 컬럼에 대해 결측치가 없는 행만 남기거나, 일부만 있는 경우도 고려 가능\n",
    "        # 여기서는 가장 중요한 첫번째 목표 페이스 컬럼이 NaN인 경우만 우선 제거\n",
    "        # 또는, 모든 목표 페이스가 NaN인 경우 제거\n",
    "        # df_model_ready.dropna(subset=final_pace_target_columns, how='all', inplace=True)\n",
    "        # 혹은, 주요 페이스 (예: 첫 구간)에 NaN이 있으면 제거\n",
    "        if final_pace_target_columns[0] in df_model_ready.columns:\n",
    "             df_model_ready.dropna(subset=[final_pace_target_columns[0]], inplace=True)\n",
    "\n",
    "\n",
    "    # 입력 특성(X)의 결측치 처리 (예: 수치형은 평균 또는 중앙값, 범주형은 최빈값 - 여기서는 OHE 후이므로 숫자형만 해당)\n",
    "    for col in existing_feature_columns: # OHE로 인해 컬럼명 변경될 수 있으므로, OHE 전 컬럼명 기준\n",
    "        if col in df_model_ready.columns and df_model_ready[col].isnull().any():\n",
    "            if pd.api.types.is_numeric_dtype(df_model_ready[col]):\n",
    "                median_val = df_model_ready[col].median()\n",
    "                df_model_ready[col].fillna(median_val, inplace=True)\n",
    "                print(f\"'{col}' 컬럼의 결측치를 중앙값 ({median_val:.2f})으로 채웠습니다.\")\n",
    "            # else: # 범주형 결측치 (OHE 전이었다면 최빈값 등으로 처리)\n",
    "                # mode_val = df_model_ready[col].mode()[0]\n",
    "                # df_model_ready[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "    print(\"결측치 처리 완료 (목표변수 NaN 행 일부 제거, 특성 NaN 중앙값 대체).\")\n",
    "    \n",
    "    # --- 5. 최종 데이터 저장 ---\n",
    "    try:\n",
    "        # 저장 경로의 디렉토리 확인 및 생성\n",
    "        output_dir_path = os.path.dirname(output_csv_path)\n",
    "        if output_dir_path and not os.path.exists(output_dir_path):\n",
    "            os.makedirs(output_dir_path)\n",
    "            print(f\"출력 디렉토리 '{output_dir_path}' 생성 완료.\")\n",
    "            \n",
    "        df_model_ready.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\n모델 학습 준비 완료된 데이터가 '{output_csv_path}'에 저장되었습니다.\")\n",
    "        print(\"\\n최종 데이터 정보 (model_ready_data):\")\n",
    "        df_model_ready.info()\n",
    "        print(\"\\n최종 데이터 상위 5행 (model_ready_data):\")\n",
    "        print(df_model_ready.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: 최종 CSV 파일 저장 중 오류 발생 - {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ★★★ 사용자 설정: 입력 파일 경로와 출력 파일 경로를 지정해주세요. ★★★\n",
    "    # 이 파일은 보스턴, 모스크바, 시카고 데이터가 합쳐지고, 날씨 정보까지 포함된 CSV입니다.\n",
    "    INPUT_FINAL_CSV_PATH = \"./real_final/FINAL_marathons_with_weather.csv\"  # <<< 경로를 실제 파일로 수정!!\n",
    "    \n",
    "    # 모델 학습에 최종적으로 사용될 데이터가 저장될 경로와 파일명\n",
    "    OUTPUT_MODEL_READY_CSV_PATH = \"./data/model_ready_data.csv\" # <<< 저장 경로 수정!!\n",
    "    # ==============================================================================\n",
    "\n",
    "    # `os` 모듈 임포트 (파일 경로 다룰 때 필요할 수 있음)\n",
    "    import os\n",
    "\n",
    "    prepare_model_ready_data(input_csv_path=INPUT_FINAL_CSV_PATH, \n",
    "                             output_csv_path=OUTPUT_MODEL_READY_CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a359d50b",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc60f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.base import clone\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# 1. 데이터 로딩\n",
    "df = pd.read_csv('./data/FINAL_marathons_with_weather.csv')\n",
    "\n",
    "# 2. 피처 및 타겟 설정\n",
    "feature_cols = ['Age_group', 'M/F', 'Sub', 'Country', 'temperature_race', 'humidity_race']\n",
    "target_cols = ['5p', '10p', '15p', 'Halfp', '25p', '30p', '35p', '40p']\n",
    "\n",
    "# 3. 결측치 제거\n",
    "df = df.dropna(subset=feature_cols + target_cols).reset_index(drop=True)\n",
    "\n",
    "# 4. Sub 기준으로 train/test 분리\n",
    "df_sub3_train, df_sub3_test = train_test_split(df[df['Sub'] == 3], test_size=0.3, random_state=42)\n",
    "df_sub4_train, df_sub4_test = train_test_split(df[df['Sub'] == 4], test_size=0.3, random_state=42)\n",
    "df_sub5_train, df_sub5_test = train_test_split(df[df['Sub'] == 5], test_size=0.3, random_state=42)\n",
    "df_rest = df[~df['Sub'].isin([3, 4, 5])]\n",
    "\n",
    "df_train = pd.concat([df_rest, df_sub3_train, df_sub4_train, df_sub5_train]).reset_index(drop=True)\n",
    "df_test = pd.concat([df_sub3_test, df_sub4_test, df_sub5_test]).reset_index(drop=True)\n",
    "\n",
    "# 5. 원-핫 인코딩\n",
    "df_full = pd.concat([df_train, df_test], keys=['train', 'test'])\n",
    "df_full = pd.get_dummies(df_full, columns=['Country'], drop_first=True)\n",
    "\n",
    "df_train_encoded = df_full.xs('train')\n",
    "df_test_encoded = df_full.xs('test')\n",
    "\n",
    "# 6. 데이터 분할\n",
    "X_train = df_train_encoded.drop(columns=target_cols).select_dtypes(include=[np.number]).values\n",
    "Y_train = df_train_encoded[target_cols].values\n",
    "X_test = df_test_encoded.drop(columns=target_cols).select_dtypes(include=[np.number]).values\n",
    "Y_test = df_test_encoded[target_cols].values\n",
    "\n",
    "# 7. 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 8. 사용할 모델들 정의\n",
    "model_dict = {\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=200, max_depth=20, random_state=42),\n",
    "    \"ExtraTrees\": ExtraTreesRegressor(n_estimators=200, max_depth=20, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42),\n",
    "    \"LightGBM\": LGBMRegressor(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42),\n",
    "    \"CatBoost\": CatBoostRegressor(iterations=200, depth=6, learning_rate=0.1, verbose=0, random_seed=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# 9. 모델 학습 및 평가\n",
    "for model_name, base_model in model_dict.items():\n",
    "    print(f\"\\n[{model_name} 학습 진행 중...]\")\n",
    "    models = []\n",
    "    for i in tqdm(range(Y_train.shape[1]), desc=f\"{model_name} Targets\"):\n",
    "        model = clone(base_model)\n",
    "        model.fit(X_train_scaled, Y_train[:, i])\n",
    "        models.append(model)\n",
    "\n",
    "    Y_pred = np.column_stack([model.predict(X_test_scaled) for model in models])\n",
    "\n",
    "    print(f\"\\n[테스트셋 성능 평가 결과 - {model_name}]\")\n",
    "    for i, col in enumerate(target_cols):\n",
    "        mae = mean_absolute_error(Y_test[:, i], Y_pred[:, i])\n",
    "        r2 = r2_score(Y_test[:, i], Y_pred[:, i])\n",
    "        print(f\"{col}: MAE = {mae:.2f} sec/km, R² = {r2:.3f}\")\n",
    "        results.append({'Model': model_name, 'Section': col, 'MAE': mae, 'R2': r2})\n",
    "\n",
    "# 10. 시각화\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "for metric in ['MAE', 'R2']:\n",
    "    plt.subplot(1, 2, 1 if metric == 'MAE' else 2)\n",
    "    sns.barplot(data=results_df, x='Model', y=metric, hue='Section')\n",
    "    plt.title(f'{metric} per Section by Model')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
