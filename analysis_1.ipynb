{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터분석 파일"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature 설명\n",
    "- 'Bib':  단순 id / 동명이인 등을 구분하기 위함\n",
    "- 'Age_group' → 19: 19세 이하 / 70: 70세 이상 / 20~69세의 경우 → 29: 25~29세\n",
    "- ‘M/F’ → Man = 0 / Woman = 1 \n",
    "- 'Country' = 국적\n",
    "- '5p' → 출발로부터 5km까지 기준 pace[sec/km](sec)\n",
    "- '15p' → 10km부터 15km까지 기준 pace[sec/km](sec)\n",
    "- 'Final_Time’ → 풀코스(42.195km) 완주 기록(sec) \n",
    "- ‘Sub’ → sub-3,4,5,6,7을 숫자로만 표현 / 3 = 완주기록 3시간 미만(sec)\n",
    "- '5k' → 출발로부터 5km되었을때의 시간 기록(sec)\n",
    "- '15k' → 출발로부터 15km되었을때의 시간 기록(sec)\n",
    "- ‘Dataset’ → 사용 데이터셋 구분 [B: 보스턴 마라톤 / C: 시카고 / M: 모스크바]\n",
    "- ‘Year’ → 해당 데이터의 년도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 5개 랜덤 샘플 ===\n",
      "         Bib  Age_group  M/F Country   5p  10p  15p    20p  25p  30p  ...  \\\n",
      "69213  69214         70    0     USA  328  326  326  328.0  330  335  ...   \n",
      "6925    6926         59    0     USA  268  269  271  273.0  275  277  ...   \n",
      "67420  67421         39    1     USA  284  295  305  312.0  323  328  ...   \n",
      "11872  11873         59    0     USA  287  283  283  286.0  292  300  ...   \n",
      "34369  34370         44    0     USA  252  249  250  256.0  270  276  ...   \n",
      "\n",
      "        15K     20K   25K    30K    35K    40K  Dataset  Year  \\\n",
      "69213  4903  6568.0  8258  10057  11882  13804        B  2017   \n",
      "6925   4068  5472.0  6876   8319   9792  11293        B  2015   \n",
      "67420  4578  6248.0  8075   9843  11681  13431        B  2017   \n",
      "11872  4252  5732.0  7307   9028  10628  12222        B  2015   \n",
      "34369  3757  5122.0  6750   8309  10123  11901        B  2016   \n",
      "\n",
      "       temperature_race  humidity_race  \n",
      "69213           21.0000         39.500  \n",
      "6925             7.0875         87.750  \n",
      "67420           21.0000         39.500  \n",
      "11872            7.0875         87.750  \n",
      "34369           15.3875         50.625  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 불러오기\n",
    "df = pd.read_csv('./data/combined_marathons_with_weather.csv')\n",
    "\n",
    "#5개 랜덤 샘플\n",
    "sample = df.sample(n=5, random_state=42)\n",
    "print(\"=== 5개 랜덤 샘플 ===\")\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 기초 통계량(summary) ===\n",
      "                Bib     Age_group           M/F            5p           10p  \\\n",
      "count  87668.000000  87668.000000  87668.000000  87668.000000  87668.000000   \n",
      "mean   43834.500000     43.890975      0.426347    307.989335    308.020190   \n",
      "std    25307.716037     11.386537      0.494548     48.638794     49.000235   \n",
      "min        1.000000     19.000000      0.000000    176.000000      6.000000   \n",
      "25%    21917.750000     34.000000      0.000000    273.000000    273.000000   \n",
      "50%    43834.500000     44.000000      0.000000    302.000000    301.000000   \n",
      "75%    65751.250000     54.000000      1.000000    336.000000    335.000000   \n",
      "max    87668.000000     70.000000      1.000000    804.000000    643.000000   \n",
      "\n",
      "                15p           20p           25p           30p           35p  \\\n",
      "count  87668.000000  79057.000000  87668.000000  87668.000000  87668.000000   \n",
      "mean     309.905724    310.100004    319.226719    323.894192    329.855569   \n",
      "std       50.530835     50.906411     57.591202     59.348660     61.636061   \n",
      "min      179.000000    181.000000     23.000000    183.000000    166.000000   \n",
      "25%      274.000000    274.000000    279.000000    283.000000    287.000000   \n",
      "50%      303.000000    303.000000    309.000000    314.000000    319.000000   \n",
      "75%      337.000000    336.000000    348.000000    354.000000    361.000000   \n",
      "max      647.000000    651.000000    743.000000    923.000000    810.000000   \n",
      "\n",
      "       ...           10K           15K           20K           25K  \\\n",
      "count  ...  87668.000000  87668.000000  79057.000000  87668.000000   \n",
      "mean   ...   3084.477689   4651.954738   6211.503232   7922.056896   \n",
      "std    ...    488.613778    748.665221   1018.121642   1343.828477   \n",
      "min    ...   1783.000000   2697.000000   3628.000000   4565.000000   \n",
      "25%    ...   2734.000000   4120.000000   5494.000000   6979.000000   \n",
      "50%    ...   3019.000000   4549.000000   6062.000000   7717.000000   \n",
      "75%    ...   3359.000000   5061.000000   6731.000000   8626.000000   \n",
      "max    ...   6436.000000   9705.000000  13027.000000  16566.000000   \n",
      "\n",
      "                30K           35K           40K          Year  \\\n",
      "count  87668.000000  87668.000000  87668.000000  87668.000000   \n",
      "mean    9668.033296  11486.168910  13300.777832   2016.195955   \n",
      "std     1684.252211   2037.858726   2377.539592      0.976790   \n",
      "min     5519.000000   6479.000000   7359.000000   2015.000000   \n",
      "25%     8488.000000  10059.000000  11639.000000   2015.000000   \n",
      "50%     9402.000000  11160.000000  12920.000000   2016.000000   \n",
      "75%    10559.000000  12582.250000  14596.000000   2017.000000   \n",
      "max    20624.000000  24691.000000  28752.000000   2018.000000   \n",
      "\n",
      "       temperature_race  humidity_race  \n",
      "count      87668.000000   87668.000000  \n",
      "mean          14.155998      61.452173  \n",
      "std            5.514232      20.646561  \n",
      "min            7.087500      39.500000  \n",
      "25%            7.087500      39.500000  \n",
      "50%           15.387500      50.625000  \n",
      "75%           21.000000      87.750000  \n",
      "max           21.000000      87.750000  \n",
      "\n",
      "[8 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#기초 통계량 (count, mean, std, min, 25%, 50%, 75%, max)\n",
    "print(\"\\n=== 기초 통계량(summary) ===\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 전체 데이터셋 결측 개수 ===\n",
      "Bib                    0\n",
      "Age_group              0\n",
      "M/F                    0\n",
      "Country                0\n",
      "5p                     0\n",
      "10p                    0\n",
      "15p                    0\n",
      "20p                 8611\n",
      "25p                    0\n",
      "30p                    0\n",
      "35p                    0\n",
      "40p                    0\n",
      "Final_Time             0\n",
      "Sub                    0\n",
      "5K                     0\n",
      "10K                    0\n",
      "15K                    0\n",
      "20K                 8611\n",
      "25K                    0\n",
      "30K                    0\n",
      "35K                    0\n",
      "40K                    0\n",
      "Dataset                0\n",
      "Year                   0\n",
      "temperature_race       0\n",
      "humidity_race          0\n",
      "wt_5K                  0\n",
      "wt_10K                 0\n",
      "wt_15K                 0\n",
      "wt_20K                 0\n",
      "wt_25K                 0\n",
      "wt_30K                 0\n",
      "wt_35K                 0\n",
      "wt_40K                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3) 전체 피처·타깃 결측 확인 (optional)\n",
    "print(\"\\n=== 전체 데이터셋 결측 개수 ===\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wt_5K  wt_10K  wt_15K  wt_20K  wt_25K  wt_30K  wt_35K  wt_40K\n",
      "0    -77     -17      -9       0      -6     -22      22     -22\n",
      "1    -77     -17      -9       0      -6     -22      22     -22\n",
      "2    -77     -17      -9       0      -6     -22      22     -22\n",
      "3    -77     -17      -9       0      -6     -22      22     -22\n",
      "4    -77     -17      -9       0      -6     -22      22     -22\n",
      "=== 5개 랜덤 샘플 ===\n",
      "         Bib  Age_group  M/F Country   5p  10p  15p  20p  25p  30p  ...  \\\n",
      "80483  80484         29    0     RUS  361  368  387  NaN  468  482  ...   \n",
      "80937  80938         34    0     RUS  318  307  298  NaN  320  302  ...   \n",
      "87080  87081         44    0     JPN  409  391  394  NaN  448  457  ...   \n",
      "81741  81742         59    0     RUS  412  419  427  NaN  559  555  ...   \n",
      "85647  85648         44    0     RUS  383  397  397  NaN  416  439  ...   \n",
      "\n",
      "       temperature_race  humidity_race  wt_5K  wt_10K  wt_15K  wt_20K  wt_25K  \\\n",
      "80483           11.0875         81.375      0       0       0       0       0   \n",
      "80937           11.0875         81.375      0       0       0       0       0   \n",
      "87080           11.0875         81.375      0       0       0       0       0   \n",
      "81741           11.0875         81.375      0       0       0       0       0   \n",
      "85647           11.0875         81.375      0       0       0       0       0   \n",
      "\n",
      "       wt_30K  wt_35K  wt_40K  \n",
      "80483       0       0       0  \n",
      "80937       0       0       0  \n",
      "87080       0       0       0  \n",
      "81741       0       0       0  \n",
      "85647       0       0       0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) 데이터 불러오기\n",
    "df = pd.read_csv('./data/combined_marathons_with_weather.csv')\n",
    "\n",
    "# 2) 보스턴 구간 경계점 고도 (m)\n",
    "boundary_alt = {\n",
    "    0.0: 149,\n",
    "    5.0:  72,\n",
    "    10.0: 55,\n",
    "    15.0: 46,\n",
    "    20.0: 46,\n",
    "    25.0: 40,\n",
    "    30.0: 18,\n",
    "    35.0: 40,\n",
    "    40.0: 18,\n",
    "}\n",
    "\n",
    "# 3) 5km 구간별 순고도 변화 계산\n",
    "seg_ends = [5.0, 10.0, 15.0, 20.0, 25.0, 30.0, 35.0, 40.0]\n",
    "seg_weights = {\n",
    "    end: boundary_alt[end] - boundary_alt[end - 5.0]\n",
    "    for end in seg_ends\n",
    "}\n",
    "\n",
    "# 4) 컬럼 초기화 (0)\n",
    "for end in seg_ends:\n",
    "    df[f'wt_{int(end)}K'] = 0\n",
    "\n",
    "# 5) 보스턴 행에만 가중치 채우기\n",
    "mask = df['Dataset'] == 'B'\n",
    "for end, w in seg_weights.items():\n",
    "    df.loc[mask, f'wt_{int(end)}K'] = w\n",
    "\n",
    "# 6) 결과 확인\n",
    "print(df.loc[mask, [f'wt_{int(e)}K' for e in seg_ends]].head())\n",
    "\n",
    "# 보스턴이 아닌(non-B) 행 중에서 5개 랜덤 샘플\n",
    "non_b_sample = df[df['Dataset'] != 'B'].sample(n=5, random_state=42)\n",
    "\n",
    "print(\"=== 5개 랜덤 샘플 ===\")\n",
    "print(non_b_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 타깃 컬럼별 NaN 개수 ===\n",
      "5p       0\n",
      "10p      0\n",
      "15p      0\n",
      "20p    299\n",
      "25p      0\n",
      "30p      0\n",
      "35p      0\n",
      "40p      0\n",
      "dtype: int64\n",
      "\n",
      "=== NaN이 있는 행(299건) 샘플 ===\n",
      "         Bib  Age_group  M/F Country   5p  10p  15p  20p  25p  30p  ...  \\\n",
      "79057  79058         34    1     RUS  211  211  207  NaN  221  212  ...   \n",
      "79058  79059         39    1     RUS  211  211  214  NaN  233  224  ...   \n",
      "79059  79060         34    0     RUS  189  190  193  NaN  202  198  ...   \n",
      "79060  79061         39    0     RUS  189  186  187  NaN  207  205  ...   \n",
      "79061  79062         44    0     RUS  195  196  195  NaN  214  213  ...   \n",
      "\n",
      "       temperature_race  humidity_race  wt_5K  wt_10K  wt_15K  wt_20K  wt_25K  \\\n",
      "79057           11.0875         81.375      0       0       0       0       0   \n",
      "79058           11.0875         81.375      0       0       0       0       0   \n",
      "79059           11.0875         81.375      0       0       0       0       0   \n",
      "79060           11.0875         81.375      0       0       0       0       0   \n",
      "79061           11.0875         81.375      0       0       0       0       0   \n",
      "\n",
      "       wt_30K  wt_35K  wt_40K  \n",
      "79057       0       0       0  \n",
      "79058       0       0       0  \n",
      "79059       0       0       0  \n",
      "79060       0       0       0  \n",
      "79061       0       0       0  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "\n",
      "=== 전체 데이터셋 결측 개수 ===\n",
      "Bib                   0\n",
      "Age_group             0\n",
      "M/F                   0\n",
      "Country               0\n",
      "5p                    0\n",
      "10p                   0\n",
      "15p                   0\n",
      "20p                 299\n",
      "25p                   0\n",
      "30p                   0\n",
      "35p                   0\n",
      "40p                   0\n",
      "Final_Time            0\n",
      "Sub                   0\n",
      "5K                    0\n",
      "10K                   0\n",
      "15K                   0\n",
      "20K                 299\n",
      "25K                   0\n",
      "30K                   0\n",
      "35K                   0\n",
      "40K                   0\n",
      "Dataset               0\n",
      "Year                  0\n",
      "temperature_race      0\n",
      "humidity_race         0\n",
      "wt_5K                 0\n",
      "wt_10K                0\n",
      "wt_15K                0\n",
      "wt_20K                0\n",
      "wt_25K                0\n",
      "wt_30K                0\n",
      "wt_35K                0\n",
      "wt_40K                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 61\u001b[0m\n\u001b[1;32m     53\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline([\n\u001b[1;32m     54\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mscaler\u001b[39m\u001b[39m'\u001b[39m, StandardScaler()),\n\u001b[1;32m     55\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m, MultiOutputRegressor(\n\u001b[1;32m     56\u001b[0m         RandomForestRegressor(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     57\u001b[0m     ))\n\u001b[1;32m     58\u001b[0m ])\n\u001b[1;32m     60\u001b[0m \u001b[39m# 6) 학습\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[1;32m     63\u001b[0m \u001b[39m# 7) 검증\u001b[39;00m\n\u001b[1;32m     64\u001b[0m Y_pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.9/site-packages/sklearn/pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 427\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    429\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.9/site-packages/sklearn/multioutput.py:242\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    240\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe base estimator should implement a fit method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 242\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mno_validation\u001b[39;49m\u001b[39m\"\u001b[39;49m, y\u001b[39m=\u001b[39;49my, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    244\u001b[0m \u001b[39mif\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    245\u001b[0m     check_classification_targets(y)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.9/site-packages/sklearn/base.py:607\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[1;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m--> 607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    608\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    609\u001b[0m     \u001b[39mif\u001b[39;00m validate_separately:\n\u001b[1;32m    610\u001b[0m         \u001b[39m# We need this because some estimators validate X and y\u001b[39;00m\n\u001b[1;32m    611\u001b[0m         \u001b[39m# separately, and in general, separately calling check_array()\u001b[39;00m\n\u001b[1;32m    612\u001b[0m         \u001b[39m# on X and y isn't equivalent to just calling check_X_y()\u001b[39;00m\n\u001b[1;32m    613\u001b[0m         \u001b[39m# :(\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.9/site-packages/sklearn/utils/validation.py:1172\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[39mif\u001b[39;00m multi_output:\n\u001b[0;32m-> 1172\u001b[0m     y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1173\u001b[0m         y,\n\u001b[1;32m   1174\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1175\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1176\u001b[0m         ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1177\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1178\u001b[0m         input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1179\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1180\u001b[0m     )\n\u001b[1;32m   1181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1182\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.9/site-packages/sklearn/utils/validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    954\u001b[0m         )\n\u001b[1;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 957\u001b[0m         _assert_all_finite(\n\u001b[1;32m    958\u001b[0m             array,\n\u001b[1;32m    959\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    960\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    961\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    964\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.9/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    123\u001b[0m     X,\n\u001b[1;32m    124\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[1;32m    125\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[1;32m    126\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[1;32m    127\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    128\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    129\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.9/site-packages/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# 2) Sub-3 검증 데이터 확보 (예: Sub == 3)\n",
    "df_sub3 = df[df['Sub'] == 3].reset_index(drop=True)\n",
    "\n",
    "# 3) 특성 및 타깃 정의\n",
    "#   X: 신체정보, 목표그룹(Sub), 환경요인, 보스턴 고도 가중치(wt_*)\n",
    "feature_cols = [\n",
    "    'M/F',          # 성별 (0=남,1=여)\n",
    "    'Age_group',    # 연령대\n",
    "    'Sub',          # 목표 그룹\n",
    "    'temperature_race',\n",
    "    'humidity_race',\n",
    "    # 보스턴만 값이 들어있는 wt_컬럼 (없으면 NaN→0 처리 필요)\n",
    "    'wt_5K', 'wt_10K', 'wt_15K', 'wt_20K',\n",
    "    'wt_25K', 'wt_30K', 'wt_35K', 'wt_40K'\n",
    "]\n",
    "\n",
    "#   Y: 5km 구간별 페이스(초/km)\n",
    "target_cols = ['5p','10p','15p','20p','25p','30p','35p','40p']\n",
    "\n",
    "#-------------------------------------------\n",
    "\n",
    "# 1) 컬럼별 결측치 개수 확인\n",
    "print(\"=== 타깃 컬럼별 NaN 개수 ===\")\n",
    "print(df_sub3[target_cols].isna().sum())\n",
    "\n",
    "# 2) 적어도 하나의 타깃이 NaN인 행 보기\n",
    "nan_rows = df_sub3[df_sub3[target_cols].isna().any(axis=1)]\n",
    "print(f\"\\n=== NaN이 있는 행({len(nan_rows)}건) 샘플 ===\")\n",
    "print(nan_rows.head())\n",
    "\n",
    "# 3) 전체 피처·타깃 결측 확인 (optional)\n",
    "print(\"\\n=== 전체 데이터셋 결측 개수 ===\")\n",
    "print(df_sub3.isna().sum())\n",
    "\n",
    "#-------------------------------------------\n",
    "\n",
    "X = df_sub3[feature_cols].fillna(0)   # NaN 이 있으면 0 으로 대체\n",
    "Y = df_sub3[target_cols]\n",
    "\n",
    "# 4) 학습/검증 분할\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 5) 파이프라인 구성 (스케일링 + 다중출력 회귀)\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', MultiOutputRegressor(\n",
    "        RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 6) 학습\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# 7) 검증\n",
    "Y_pred = pipeline.predict(X_val)\n",
    "\n",
    "print(\"=== 구간별 MAE & R² ===\")\n",
    "for i, col in enumerate(target_cols):\n",
    "    mae = mean_absolute_error(Y_val.iloc[:, i], Y_pred[:, i])\n",
    "    r2  = r2_score(Y_val.iloc[:, i],    Y_pred[:, i])\n",
    "    print(f\"{col}: MAE={mae:.2f} sec/km,  R²={r2:.3f}\")\n",
    "\n",
    "# 8) 예측 예시: 30세 남성, Sub-3, 10℃·80% 습도, 보스턴 고도 가중치 적용\n",
    "example = pd.DataFrame([{\n",
    "    'M/F': 0,\n",
    "    'Age_group': 30,\n",
    "    'Sub': 3,\n",
    "    'temperature_race': 10,\n",
    "    'humidity_race': 80,\n",
    "    'wt_5K':  -77,\n",
    "    'wt_10K': -17,\n",
    "    'wt_15K':  -9,\n",
    "    'wt_20K':   0,\n",
    "    'wt_25K': -6,\n",
    "    'wt_30K': -22,\n",
    "    'wt_35K': +22,\n",
    "    'wt_40K': -22\n",
    "}])\n",
    "pred = pipeline.predict(example)\n",
    "print(\"\\n예측된 구간별 페이스(sec/km):\")\n",
    "print(dict(zip(target_cols, pred[0])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datasci)",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
