{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d72f41-2584-4fbd-b508-312ee9a159a8",
   "metadata": {},
   "source": [
    "# Moscow Marathon Full Results 2018\n",
    "\n",
    "\n",
    "## 1_full_results_mm_2018.csv\n",
    "\n",
    "Columns : {Bib, finish_time_sec, finish_time_result, race, pace_sec, pace(minpkm), pace(kmph), half_pace_sec, half_pace(minpkm), half_pace(kmph), gender_en, agev name_en, location_city_ru, location_city_en, country_code_alpha_3, flag_DNF, flag_all_split_exist, race_uniform_index}\n",
    "\n",
    "Data : {1, 8911, 2h 28min 31sec, 42.195 km, 211.1861595, 3:31 min/km 17.0 km/h, 208.3185212, 3:28 min/km, 17.3 km/h, Female, 30, Sardana Trofimova, –Ø–∫—É—Ç—Å–∫, Yakutsk, RUS, 0, 1, 0.000132899}\n",
    "\n",
    "## 1_split_results_mm_2018.csv\n",
    "\n",
    "Columns : {bib, split_name, split, split_time_sec, split_time_result, split_pace_sec, split_pace(minpkm), split_pace(kmph), split_uniform_index}\n",
    "\n",
    "Data : {11, Kirui, Geoffrey, 24, M, Keringet, KEN, 0:15:25, 0:30:28, 0:45:44, 1:01:15, 1:04:35, 1:16:59, 1:33:01, 1:48:19, 2:02:53, 0:04:57, - 2:09:37, 1, 1, 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998cb8bc-a1de-40a6-913a-833796954086",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/1_full_results_mm_2018.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 데이터 불러오기\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m full_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/1_full_results_mm_2018.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m split_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/1_split_results_mm_2018.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# bib 통일\u001b[39;00m\n",
      "File \u001b[1;32me:\\anaconda\\envs\\ml_venu\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\ml_venu\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32me:\\anaconda\\envs\\ml_venu\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\ml_venu\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32me:\\anaconda\\envs\\ml_venu\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/1_full_results_mm_2018.csv'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "full_df = pd.read_csv('./data/1_full_results_mm_2018.csv')\n",
    "split_df = pd.read_csv('./data/1_split_results_mm_2018.csv')\n",
    "\n",
    "# bib 통일\n",
    "full_df['bib'] = full_df['bib'].astype(str)\n",
    "split_df['bib'] = split_df['bib'].astype(str)\n",
    "\n",
    "# --------------------------\n",
    "# split_time_sec pivot (5K~40K만)\n",
    "split_time = split_df.pivot_table(index='bib', columns='split_name', values='split_time_sec')\n",
    "\n",
    "# Half marathon, Marathon 열 제거\n",
    "split_time = split_time.drop(columns=['Half marathon', 'Marathon'], errors='ignore')\n",
    "\n",
    "# ' km' 제거 후 'K' 붙이기\n",
    "split_time.columns = [col.replace(' km', '') + 'K' for col in split_time.columns]\n",
    "split_time = split_time.apply(pd.to_numeric, errors='coerce')\n",
    "split_time.reset_index(inplace=True)\n",
    "\n",
    "# --------------------------\n",
    "# split_pace_sec pivot (5p~40p만)\n",
    "split_pace = split_df.pivot_table(index='bib', columns='split_name', values='split_pace_sec')\n",
    "split_pace = split_pace.drop(columns=['Half marathon', 'Marathon'], errors='ignore')\n",
    "\n",
    "split_pace.columns = [col.replace(' km', '') + 'p' for col in split_pace.columns]\n",
    "split_pace = split_pace.apply(pd.to_numeric, errors='coerce')\n",
    "split_pace.reset_index(inplace=True)\n",
    "\n",
    "# --------------------------\n",
    "# 필요한 컬럼 선택 및 전처리\n",
    "reduced_df = full_df[['bib', 'age', 'gender_en', 'country_code_alpha_3', 'finish_time_sec']].copy()\n",
    "reduced_df.rename(columns={\n",
    "    'bib': 'Bib',\n",
    "    'age': 'Age',\n",
    "    'gender_en': 'M/F',\n",
    "    'country_code_alpha_3': 'Country',\n",
    "    'finish_time_sec': 'Final_Time'\n",
    "}, inplace=True)\n",
    "\n",
    "# Final_Time이 NaN인 경우 제거\n",
    "reduced_df = reduced_df.dropna(subset=['Final_Time'])\n",
    "\n",
    "# Age_group (19이하 → 19, ..., 70 이상 → 70)\n",
    "def age_group(age):\n",
    "    if age <= 19:\n",
    "        return 19\n",
    "    elif age >= 70:\n",
    "        return 70\n",
    "    else:\n",
    "        return (age // 5) * 5 + 4  # 20~24 → 24, 25~29 → 29, ...\n",
    "\n",
    "reduced_df['Age_group'] = reduced_df['Age'].apply(age_group)\n",
    "\n",
    "# M/F: Male → 0, Female → 1\n",
    "reduced_df['M/F'] = reduced_df['M/F'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "# Sub 그룹핑\n",
    "def set_sub_group(seconds):\n",
    "    if pd.isna(seconds):\n",
    "        return pd.NA\n",
    "    hours = seconds / 3600\n",
    "    if hours < 3:\n",
    "        return 3\n",
    "    elif hours < 4:\n",
    "        return 4\n",
    "    elif hours < 5:\n",
    "        return 5\n",
    "    elif hours < 6:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "reduced_df['Sub'] = reduced_df['Final_Time'].apply(set_sub_group).astype('Int64')\n",
    "\n",
    "# --------------------------\n",
    "# 병합\n",
    "merged = reduced_df.merge(split_time, how='left', left_on='Bib', right_on='bib')\n",
    "merged = merged.merge(split_pace, how='left', on='bib')\n",
    "merged.drop(columns=['bib'], inplace=True)\n",
    "\n",
    "# Dataset 컬럼 추가\n",
    "merged['Dataset'] = 'M'\n",
    "\n",
    "# --------------------------\n",
    "# 컬럼 순서 지정 (5~40K, 5~40p만 포함)\n",
    "pace_cols = [f'{k}p' for k in range(5, 45, 5)]\n",
    "time_cols = [f'{k}K' for k in range(5, 45, 5)]\n",
    "\n",
    "columns_order = ['Bib', 'Age_group', 'M/F', 'Country'] + \\\n",
    "                pace_cols + ['Final_Time', 'Sub'] + \\\n",
    "                time_cols + ['Dataset']\n",
    "\n",
    "# 존재하는 컬럼만 유지\n",
    "columns_order = [col for col in columns_order if col in merged.columns]\n",
    "\n",
    "# 결측치 제거\n",
    "Moscow_df = merged[columns_order].dropna()\n",
    "\n",
    "# Bib 재설정\n",
    "Moscow_df['Bib'] = range(1, len(Moscow_df) + 1)\n",
    "cols = Moscow_df.columns.tolist()\n",
    "cols.remove('Bib')\n",
    "Moscow_df = Moscow_df[['Bib'] + cols]\n",
    "\n",
    "# int 변환\n",
    "int_cols = Moscow_df.columns.difference(['Country', 'Dataset'])\n",
    "Moscow_df[int_cols] = Moscow_df[int_cols].astype(int)\n",
    "\n",
    "# 저장\n",
    "Moscow_df.to_csv('./data/Moscow_Marathon_Processed.csv', index=False)\n",
    "\n",
    "# 확인\n",
    "print(Moscow_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3ed32-07ab-4a38-9976-eade76903ebf",
   "metadata": {},
   "source": [
    "# Finishers Boston Marathon 2015, 2016 & 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e608019-0082-42c3-9da0-3453de163d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bib  Age_group  M/F Country   5p  10p  15p  20p  25p  30p  ...  Sub   5K  \\\n",
      "0    1         29    0     ETH  176  178  179  181  182  184  ...    4  883   \n",
      "1    2         34    0     ETH  176  178  179  181  182  183  ...    4  883   \n",
      "2    3         29    0     KEN  176  178  179  181  182  184  ...    4  883   \n",
      "3    4         29    0     KEN  176  178  180  181  182  184  ...    4  883   \n",
      "4    5         34    0     KEN  176  178  179  181  182  184  ...    4  883   \n",
      "\n",
      "    10K   15K   20K   25K   30K   35K   40K  Dataset  \n",
      "0  1783  2697  3629  4567  5520  6479  7359        B  \n",
      "1  1783  2698  3628  4567  5519  6479  7362        B  \n",
      "2  1783  2697  3629  4567  5520  6479  7381        B  \n",
      "3  1784  2701  3629  4567  5520  6483  7427        B  \n",
      "4  1784  2698  3628  4567  5520  6479  7407        B  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 로드\n",
    "df_15 = pd.read_csv('./data/marathon_results_2015.csv')\n",
    "df_16 = pd.read_csv('./data/marathon_results_2016.csv')\n",
    "df_17 = pd.read_csv('./data/marathon_results_2017.csv')\n",
    "\n",
    "# 연도 컬럼 추가\n",
    "df_15['Year'] = 2015\n",
    "df_16['Year'] = 2016\n",
    "df_17['Year'] = 2017\n",
    "\n",
    "# 데이터 통합\n",
    "df = pd.concat([df_15, df_16, df_17], ignore_index=True)\n",
    "\n",
    "# 불필요한 컬럼 제거\n",
    "drop_cols = ['Unnamed: 0', 'Unnamed: 8', 'Unnamed: 9', 'State', 'Citizen', 'Proj Time']\n",
    "df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
    "\n",
    "# 시간형 컬럼 처리 대상: 21K는 제거 대상\n",
    "time_cols = ['5K', '10K', '15K', '20K', '25K', '30K', '35K', '40K', 'Pace', 'Official Time']\n",
    "for col in time_cols:\n",
    "    df[col] = pd.to_timedelta(df[col], errors='coerce')\n",
    "\n",
    "# 초 단위로 변환\n",
    "for col in ['5K', '10K', '15K', '20K', '25K', '30K', '35K', '40K', 'Official Time']:\n",
    "    df[col] = df[col].dt.total_seconds()\n",
    "\n",
    "# 컬럼명 변경\n",
    "df.rename(columns={'Official Time': 'Final_Time'}, inplace=True)\n",
    "\n",
    "# 페이스 계산 (21K 제외)\n",
    "distance_km = {'5K': 5, '10K': 10, '15K': 15, '20K': 20, '25K': 25, '30K': 30, '35K': 35, '40K': 40}\n",
    "for dist, km in distance_km.items():\n",
    "    pace_col = dist.replace('K', 'p')\n",
    "    df[pace_col] = df[dist] / km\n",
    "\n",
    "# Age_group 지정\n",
    "def age_group(age):\n",
    "    if age < 20:\n",
    "        return 19\n",
    "    elif age < 25:\n",
    "        return 24\n",
    "    elif age < 30:\n",
    "        return 29\n",
    "    elif age < 35:\n",
    "        return 34\n",
    "    elif age < 40:\n",
    "        return 39\n",
    "    elif age < 45:\n",
    "        return 44\n",
    "    elif age < 50:\n",
    "        return 49\n",
    "    elif age < 55:\n",
    "        return 54\n",
    "    elif age < 60:\n",
    "        return 59\n",
    "    elif age < 65:\n",
    "        return 64\n",
    "    elif age < 70:\n",
    "        return 69\n",
    "    else:\n",
    "        return 70\n",
    "\n",
    "df['Age_group'] = df['Age'].apply(age_group)\n",
    "\n",
    "# 성별 인코딩\n",
    "df['M/F'] = df['M/F'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Sub (시간 그룹)\n",
    "def sub_group(time_sec):\n",
    "    hours = time_sec / 3600\n",
    "    if hours <= 2:\n",
    "        return 3\n",
    "    elif hours <= 3:\n",
    "        return 4\n",
    "    elif hours <= 4:\n",
    "        return 5\n",
    "    elif hours <= 5:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "df['Sub'] = df['Final_Time'].apply(sub_group)\n",
    "\n",
    "# 필요한 컬럼만 추출\n",
    "base_cols = ['Bib', 'Age_group', 'M/F', 'Country']\n",
    "pace_cols = [k.replace('K', 'p') for k in distance_km.keys()]\n",
    "time_cols = list(distance_km.keys())\n",
    "final_cols = ['Final_Time', 'Sub']\n",
    "df['Dataset'] = 'B'\n",
    "\n",
    "ordered_cols = base_cols + pace_cols + final_cols + time_cols + ['Dataset']\n",
    "df = df[ordered_cols]\n",
    "\n",
    "# 결측치 제거 및 Bib 재할당\n",
    "df = df.dropna()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['Bib'] = df.index + 1\n",
    "\n",
    "# 숫자형 컬럼 int로 변환\n",
    "int_cols = df.columns.difference(['Country', 'Dataset'])\n",
    "df[int_cols] = df[int_cols].astype(int)\n",
    "\n",
    "# 저장\n",
    "df.to_csv('./data/boston_processed.csv', index=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef1d66-ef92-4579-aa23-33c3da631e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 존재 여부:\n",
      " 17222\n",
      "Dataset 분포:\n",
      " Dataset\n",
      "B    79057\n",
      "M     8611\n",
      "Name: count, dtype: int64\n",
      "✔️ 병합된 데이터 저장 완료! 총 샘플 수: 87668\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "boston_path = './data/boston_processed.csv'\n",
    "moscow_path = './data/Moscow_Marathon_Processed.csv'\n",
    "\n",
    "# 데이터 불러오기\n",
    "df_boston = pd.read_csv(boston_path)\n",
    "df_moscow = pd.read_csv(moscow_path)\n",
    "\n",
    "# 병합 (인덱스 초기화)\n",
    "df_merged = pd.concat([df_boston, df_moscow], ignore_index=True)\n",
    "\n",
    "# Bib 재설정 (1부터 시작)\n",
    "df_merged['Bib'] = range(1, len(df_merged) + 1)\n",
    "\n",
    "# Bib을 맨 앞으로 이동\n",
    "cols = df_merged.columns.tolist()\n",
    "cols.remove('Bib')\n",
    "df_merged = df_merged[['Bib'] + cols]\n",
    "\n",
    "# 결측치 확인 (추가적인 안전 확인)\n",
    "print(\"결측치 존재 여부:\\n\", df_merged.isnull().sum().sum())  # 0이면 OK\n",
    "\n",
    "# Dataset별 샘플 수 확인\n",
    "print(\"Dataset 분포:\\n\", df_merged['Dataset'].value_counts())\n",
    "\n",
    "# 저장\n",
    "df_merged.to_csv('./data/combined_Marathon_Data.csv', index=False)\n",
    "print(f\"✔️ 병합된 데이터 저장 완료! 총 샘플 수: {len(df_merged)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964ac29-a7c3-4b4d-8f3b-d53f18d18b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합된 데이터 샘플 수: 79057\n",
      "결측치 확인: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "boston_path = './data/boston_processed.csv'\n",
    "moscow_path = './data/Moscow_Marathon_Processed.csv'\n",
    "\n",
    "# 데이터 불러오기\n",
    "df_boston = pd.read_csv(boston_path)\n",
    "df_moscow = pd.read_csv(moscow_path)\n",
    "\n",
    "# 데이터 병합\n",
    "df_merged = pd.concat([df_boston, df_moscow], ignore_index=True)\n",
    "\n",
    "# 결측치 제거\n",
    "df_merged.dropna(inplace=True)\n",
    "\n",
    "# 정수형 변환 (Country, Dataset 제외)\n",
    "exclude_cols = ['Country', 'Dataset']\n",
    "int_cols = df_merged.columns.difference(exclude_cols)\n",
    "df_merged[int_cols] = df_merged[int_cols].astype(int)\n",
    "\n",
    "# Bib 재설정 및 정렬\n",
    "df_merged['Bib'] = range(1, len(df_merged) + 1)\n",
    "cols = df_merged.columns.tolist()\n",
    "cols.remove('Bib')\n",
    "df_merged = df_merged[['Bib'] + cols]\n",
    "\n",
    "# 저장\n",
    "df_merged.to_csv('./data/combined_Marathon_Data.csv', index=False)\n",
    "\n",
    "print(\"병합된 데이터 샘플 수:\", len(df_merged))\n",
    "print(\"결측치 확인:\", df_merged.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc67c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 각 데이터셋 불러오기\n",
    "combined_df = pd.read_csv(\"./data/Combined_Marathon_Data.csv\")      # 보스턴 등 기존 데이터\n",
    "chicago_df = pd.read_csv(\"./data/chicago_data_processed.csv\")       # 시카고 데이터\n",
    "\n",
    "# 두 데이터셋을 하나로 병합 (인덱스 재정렬 포함)\n",
    "merged_df = pd.concat([combined_df, chicago_df], ignore_index=True)\n",
    "\n",
    "# (선택) 저장하고 싶다면\n",
    "merged_df.to_csv(\"./data/merged_marathon_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2df12-2ec3-4362-84cc-6fd275daa12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8611"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_moscow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36e8d0-3dfc-4803-b18a-2ce4408a0acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN 또는 inf 값을 포함한 행 수: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bib</th>\n",
       "      <th>Age_group</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Country</th>\n",
       "      <th>5p</th>\n",
       "      <th>10p</th>\n",
       "      <th>15p</th>\n",
       "      <th>20p</th>\n",
       "      <th>25p</th>\n",
       "      <th>30p</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub</th>\n",
       "      <th>5K</th>\n",
       "      <th>10K</th>\n",
       "      <th>15K</th>\n",
       "      <th>20K</th>\n",
       "      <th>25K</th>\n",
       "      <th>30K</th>\n",
       "      <th>35K</th>\n",
       "      <th>40K</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Bib, Age_group, M/F, Country, 5p, 10p, 15p, 20p, 25p, 30p, 35p, 40p, Final_Time, Sub, 5K, 10K, 15K, 20K, 25K, 30K, 35K, 40K, Dataset]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 수치형 컬럼만 선택\n",
    "numeric_df = df_merged.select_dtypes(include=[np.number])\n",
    "\n",
    "# NaN 또는 inf 값이 있는 행의 마스크\n",
    "non_finite_mask = ~np.isfinite(numeric_df)\n",
    "\n",
    "# 마스크로 해당 행 추출\n",
    "rows_with_nan_or_inf = df_merged[non_finite_mask.any(axis=1)]\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"NaN 또는 inf 값을 포함한 행 수: {len(rows_with_nan_or_inf)}\")\n",
    "display(rows_with_nan_or_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186935f-fb9e-463d-ab32-51bd2f9a42af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset = 'M'인 행 수: 0\n",
      "Dataset = 'B'인 행 수: 79057\n"
     ]
    }
   ],
   "source": [
    "count_M = (df_merged['Dataset'] == 'M').sum()\n",
    "count_B = (df_merged['Dataset'] == 'B').sum()\n",
    "\n",
    "print(f\"Dataset = 'M'인 행 수: {count_M}\")\n",
    "print(f\"Dataset = 'B'인 행 수: {count_B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e41d6d-8c67-4a24-baf1-3fb8e14c0ffd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# NaN 또는 inf 값이 있는 행을 찾기 위한 마스크 생성\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m non_finite_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misfinite(df_merged)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 마스크를 사용하여 해당 행만 추출\u001b[39;00m\n\u001b[1;32m      7\u001b[0m rows_with_nan_or_inf \u001b[38;5;241m=\u001b[39m df_merged[non_finite_mask\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:2171\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2167\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   2168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_ufunc__\u001b[39m(\n\u001b[1;32m   2169\u001b[0m     \u001b[38;5;28mself\u001b[39m, ufunc: np\u001b[38;5;241m.\u001b[39mufunc, method: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   2170\u001b[0m ):\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arraylike\u001b[38;5;241m.\u001b[39marray_ufunc(\u001b[38;5;28mself\u001b[39m, ufunc, method, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:407\u001b[0m, in \u001b[0;36marray_ufunc\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__call__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs:\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# for np.<ufunc>(..) calls\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m# kwargs cannot necessarily be handled block-by-block, so only\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# take this path if there are no kwargs\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[0;32m--> 407\u001b[0m     result \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mgetattr\u001b[39m(ufunc, method))\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# otherwise specific ufunc methods (eg np.<ufunc>.accumulate(..))\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;66;03m# Those can have an axis keyword and thus can't be called block-by-block\u001b[39;00m\n\u001b[1;32m    411\u001b[0m     result \u001b[38;5;241m=\u001b[39m default_array_ufunc(inputs[\u001b[38;5;241m0\u001b[39m], ufunc, method, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:361\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m obj[b\u001b[38;5;241m.\u001b[39mmgr_locs\u001b[38;5;241m.\u001b[39mindexer]\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[0;32m--> 361\u001b[0m     applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NaN 또는 inf 값이 있는 행을 찾기 위한 마스크 생성\n",
    "non_finite_mask = ~np.isfinite(df_merged)\n",
    "\n",
    "# 마스크를 사용하여 해당 행만 추출\n",
    "rows_with_nan_or_inf = df_merged[non_finite_mask.any(axis=1)]\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"NaN 또는 inf가 포함된 행 수: {len(rows_with_nan_or_inf)}\")\n",
    "display(rows_with_nan_or_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218f1fa-bf40-435c-9020-ed6c6957b9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
